{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.6,
  "eval_steps": 1000,
  "global_step": 81000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.6152716875076294,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 1.6661,
      "mean_token_accuracy": 0.6041158883273602,
      "num_tokens": 104933.0,
      "step": 100
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.7743319272994995,
      "learning_rate": 4.995045045045045e-05,
      "loss": 1.4012,
      "mean_token_accuracy": 0.6467504589259625,
      "num_tokens": 210472.0,
      "step": 200
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.9501376152038574,
      "learning_rate": 4.99004004004004e-05,
      "loss": 1.3163,
      "mean_token_accuracy": 0.660673740208149,
      "num_tokens": 315566.0,
      "step": 300
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 1.1686899662017822,
      "learning_rate": 4.985035035035035e-05,
      "loss": 1.2907,
      "mean_token_accuracy": 0.6645649327337741,
      "num_tokens": 420463.0,
      "step": 400
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 1.3755509853363037,
      "learning_rate": 4.98003003003003e-05,
      "loss": 1.2631,
      "mean_token_accuracy": 0.6707522110641002,
      "num_tokens": 525334.0,
      "step": 500
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.3535138368606567,
      "learning_rate": 4.9750250250250253e-05,
      "loss": 1.2671,
      "mean_token_accuracy": 0.6660044246912002,
      "num_tokens": 631561.0,
      "step": 600
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 1.533384919166565,
      "learning_rate": 4.9700200200200204e-05,
      "loss": 1.2654,
      "mean_token_accuracy": 0.6691585329174995,
      "num_tokens": 737339.0,
      "step": 700
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 1.4406598806381226,
      "learning_rate": 4.9650150150150154e-05,
      "loss": 1.2486,
      "mean_token_accuracy": 0.6719877745211125,
      "num_tokens": 842392.0,
      "step": 800
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9605002403259277,
      "learning_rate": 4.96001001001001e-05,
      "loss": 1.2489,
      "mean_token_accuracy": 0.6725909082591534,
      "num_tokens": 948198.0,
      "step": 900
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 1.4268221855163574,
      "learning_rate": 4.9550050050050054e-05,
      "loss": 1.2391,
      "mean_token_accuracy": 0.6747113940864802,
      "num_tokens": 1051893.0,
      "step": 1000
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 1.4212126731872559,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 1.2103,
      "mean_token_accuracy": 0.6781203755736351,
      "num_tokens": 1155092.0,
      "step": 1100
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 1.616524338722229,
      "learning_rate": 4.9449949949949954e-05,
      "loss": 1.2199,
      "mean_token_accuracy": 0.6771348966658115,
      "num_tokens": 1258698.0,
      "step": 1200
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 1.6604816913604736,
      "learning_rate": 4.9399899899899904e-05,
      "loss": 1.2256,
      "mean_token_accuracy": 0.6765719710290432,
      "num_tokens": 1363747.0,
      "step": 1300
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 1.6672619581222534,
      "learning_rate": 4.934984984984985e-05,
      "loss": 1.2048,
      "mean_token_accuracy": 0.6814683267474174,
      "num_tokens": 1467898.0,
      "step": 1400
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.867077350616455,
      "learning_rate": 4.92997997997998e-05,
      "loss": 1.2276,
      "mean_token_accuracy": 0.6754578539729118,
      "num_tokens": 1573813.0,
      "step": 1500
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 1.5050021409988403,
      "learning_rate": 4.9249749749749754e-05,
      "loss": 1.2063,
      "mean_token_accuracy": 0.6792049370706081,
      "num_tokens": 1679592.0,
      "step": 1600
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 1.4664812088012695,
      "learning_rate": 4.9199699699699704e-05,
      "loss": 1.2116,
      "mean_token_accuracy": 0.6782091471552849,
      "num_tokens": 1783381.0,
      "step": 1700
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7582976818084717,
      "learning_rate": 4.9149649649649654e-05,
      "loss": 1.2135,
      "mean_token_accuracy": 0.679995253533125,
      "num_tokens": 1889337.0,
      "step": 1800
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 1.7535237073898315,
      "learning_rate": 4.90995995995996e-05,
      "loss": 1.2058,
      "mean_token_accuracy": 0.6827492979168892,
      "num_tokens": 1994957.0,
      "step": 1900
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 1.7974143028259277,
      "learning_rate": 4.904954954954955e-05,
      "loss": 1.2281,
      "mean_token_accuracy": 0.675719965994358,
      "num_tokens": 2100328.0,
      "step": 2000
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 1.7934757471084595,
      "learning_rate": 4.8999499499499504e-05,
      "loss": 1.2197,
      "mean_token_accuracy": 0.6770843051373958,
      "num_tokens": 2205842.0,
      "step": 2100
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 1.7310307025909424,
      "learning_rate": 4.8949949949949955e-05,
      "loss": 1.1912,
      "mean_token_accuracy": 0.6830700175464153,
      "num_tokens": 2310550.0,
      "step": 2200
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 1.7414042949676514,
      "learning_rate": 4.8899899899899905e-05,
      "loss": 1.1958,
      "mean_token_accuracy": 0.6798916633427143,
      "num_tokens": 2414653.0,
      "step": 2300
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.5672270059585571,
      "learning_rate": 4.8849849849849855e-05,
      "loss": 1.203,
      "mean_token_accuracy": 0.6798084712028504,
      "num_tokens": 2520136.0,
      "step": 2400
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 2.0993564128875732,
      "learning_rate": 4.87997997997998e-05,
      "loss": 1.2112,
      "mean_token_accuracy": 0.6825525373965502,
      "num_tokens": 2627091.0,
      "step": 2500
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 1.832352638244629,
      "learning_rate": 4.874974974974975e-05,
      "loss": 1.2136,
      "mean_token_accuracy": 0.6813264949619771,
      "num_tokens": 2733569.0,
      "step": 2600
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.139949321746826,
      "learning_rate": 4.8699699699699706e-05,
      "loss": 1.1896,
      "mean_token_accuracy": 0.6832384397089482,
      "num_tokens": 2837091.0,
      "step": 2700
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 1.6250784397125244,
      "learning_rate": 4.8649649649649656e-05,
      "loss": 1.1948,
      "mean_token_accuracy": 0.681514585018158,
      "num_tokens": 2941472.0,
      "step": 2800
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 2.01796555519104,
      "learning_rate": 4.8599599599599606e-05,
      "loss": 1.1882,
      "mean_token_accuracy": 0.6831334961950779,
      "num_tokens": 3047043.0,
      "step": 2900
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.7483320236206055,
      "learning_rate": 4.854954954954955e-05,
      "loss": 1.1902,
      "mean_token_accuracy": 0.683029429987073,
      "num_tokens": 3152069.0,
      "step": 3000
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 1.7979906797409058,
      "learning_rate": 4.84994994994995e-05,
      "loss": 1.1845,
      "mean_token_accuracy": 0.6845701120793819,
      "num_tokens": 3256933.0,
      "step": 3100
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 1.819664716720581,
      "learning_rate": 4.844944944944945e-05,
      "loss": 1.1975,
      "mean_token_accuracy": 0.6832326391339302,
      "num_tokens": 3362945.0,
      "step": 3200
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 1.7829033136367798,
      "learning_rate": 4.8399399399399406e-05,
      "loss": 1.1816,
      "mean_token_accuracy": 0.6848492163419724,
      "num_tokens": 3467368.0,
      "step": 3300
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 1.7328821420669556,
      "learning_rate": 4.8349349349349356e-05,
      "loss": 1.1988,
      "mean_token_accuracy": 0.6819065534323454,
      "num_tokens": 3572510.0,
      "step": 3400
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 1.785836100578308,
      "learning_rate": 4.82992992992993e-05,
      "loss": 1.1763,
      "mean_token_accuracy": 0.6860863256454468,
      "num_tokens": 3676278.0,
      "step": 3500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7206501960754395,
      "learning_rate": 4.824924924924925e-05,
      "loss": 1.1837,
      "mean_token_accuracy": 0.6847426253557205,
      "num_tokens": 3780197.0,
      "step": 3600
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 1.6994117498397827,
      "learning_rate": 4.81991991991992e-05,
      "loss": 1.173,
      "mean_token_accuracy": 0.6863608153164387,
      "num_tokens": 3886829.0,
      "step": 3700
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 1.680412769317627,
      "learning_rate": 4.8149149149149156e-05,
      "loss": 1.166,
      "mean_token_accuracy": 0.6889920477569104,
      "num_tokens": 3990788.0,
      "step": 3800
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 1.5577569007873535,
      "learning_rate": 4.8099099099099106e-05,
      "loss": 1.1913,
      "mean_token_accuracy": 0.6852011851966381,
      "num_tokens": 4096938.0,
      "step": 3900
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 2.0292165279388428,
      "learning_rate": 4.804904904904905e-05,
      "loss": 1.1749,
      "mean_token_accuracy": 0.6870132732391357,
      "num_tokens": 4202576.0,
      "step": 4000
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 1.8399219512939453,
      "learning_rate": 4.7998998998999e-05,
      "loss": 1.1623,
      "mean_token_accuracy": 0.6894414049386978,
      "num_tokens": 4305345.0,
      "step": 4100
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 1.8939411640167236,
      "learning_rate": 4.794894894894895e-05,
      "loss": 1.169,
      "mean_token_accuracy": 0.6872388915717602,
      "num_tokens": 4409028.0,
      "step": 4200
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 1.9219934940338135,
      "learning_rate": 4.78988988988989e-05,
      "loss": 1.1814,
      "mean_token_accuracy": 0.685929380506277,
      "num_tokens": 4513626.0,
      "step": 4300
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 2.321721315383911,
      "learning_rate": 4.784884884884885e-05,
      "loss": 1.1951,
      "mean_token_accuracy": 0.6821405819803477,
      "num_tokens": 4620356.0,
      "step": 4400
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6501432657241821,
      "learning_rate": 4.77987987987988e-05,
      "loss": 1.1797,
      "mean_token_accuracy": 0.6850539983808994,
      "num_tokens": 4724666.0,
      "step": 4500
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 1.6730284690856934,
      "learning_rate": 4.774874874874875e-05,
      "loss": 1.1665,
      "mean_token_accuracy": 0.6866761541366577,
      "num_tokens": 4829793.0,
      "step": 4600
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 1.9017385244369507,
      "learning_rate": 4.76986986986987e-05,
      "loss": 1.1723,
      "mean_token_accuracy": 0.6874158136546612,
      "num_tokens": 4935752.0,
      "step": 4700
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.9413543939590454,
      "learning_rate": 4.764864864864865e-05,
      "loss": 1.1714,
      "mean_token_accuracy": 0.6877007434517145,
      "num_tokens": 5042124.0,
      "step": 4800
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 2.02205228805542,
      "learning_rate": 4.75985985985986e-05,
      "loss": 1.1756,
      "mean_token_accuracy": 0.686731870919466,
      "num_tokens": 5148446.0,
      "step": 4900
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 1.7718614339828491,
      "learning_rate": 4.754854854854855e-05,
      "loss": 1.1879,
      "mean_token_accuracy": 0.6862421979010105,
      "num_tokens": 5255463.0,
      "step": 5000
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 2.0257766246795654,
      "learning_rate": 4.74984984984985e-05,
      "loss": 1.2017,
      "mean_token_accuracy": 0.6822911494970322,
      "num_tokens": 5363897.0,
      "step": 5100
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 1.8179380893707275,
      "learning_rate": 4.744844844844845e-05,
      "loss": 1.1653,
      "mean_token_accuracy": 0.6871660736203193,
      "num_tokens": 5467430.0,
      "step": 5200
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 1.6645787954330444,
      "learning_rate": 4.73983983983984e-05,
      "loss": 1.1719,
      "mean_token_accuracy": 0.6869436222314834,
      "num_tokens": 5571501.0,
      "step": 5300
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.648169755935669,
      "learning_rate": 4.734834834834835e-05,
      "loss": 1.166,
      "mean_token_accuracy": 0.688105838149786,
      "num_tokens": 5675328.0,
      "step": 5400
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 1.7386678457260132,
      "learning_rate": 4.72982982982983e-05,
      "loss": 1.172,
      "mean_token_accuracy": 0.686443343013525,
      "num_tokens": 5780466.0,
      "step": 5500
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 1.6545957326889038,
      "learning_rate": 4.724824824824825e-05,
      "loss": 1.1584,
      "mean_token_accuracy": 0.6898394379019738,
      "num_tokens": 5884798.0,
      "step": 5600
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 1.5979225635528564,
      "learning_rate": 4.71981981981982e-05,
      "loss": 1.176,
      "mean_token_accuracy": 0.6852017262578011,
      "num_tokens": 5989315.0,
      "step": 5700
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 1.731897234916687,
      "learning_rate": 4.714814814814815e-05,
      "loss": 1.1815,
      "mean_token_accuracy": 0.6858785089850425,
      "num_tokens": 6094124.0,
      "step": 5800
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 2.0730109214782715,
      "learning_rate": 4.70980980980981e-05,
      "loss": 1.1628,
      "mean_token_accuracy": 0.688543565645814,
      "num_tokens": 6199391.0,
      "step": 5900
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.8486137390136719,
      "learning_rate": 4.704804804804805e-05,
      "loss": 1.1563,
      "mean_token_accuracy": 0.6912174066901207,
      "num_tokens": 6302810.0,
      "step": 6000
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 1.6752662658691406,
      "learning_rate": 4.6997997997998e-05,
      "loss": 1.1639,
      "mean_token_accuracy": 0.6890015771985054,
      "num_tokens": 6408348.0,
      "step": 6100
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 2.0686051845550537,
      "learning_rate": 4.694794794794795e-05,
      "loss": 1.1627,
      "mean_token_accuracy": 0.6880886000394821,
      "num_tokens": 6512692.0,
      "step": 6200
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.758304238319397,
      "learning_rate": 4.68978978978979e-05,
      "loss": 1.1771,
      "mean_token_accuracy": 0.6860556836426258,
      "num_tokens": 6620977.0,
      "step": 6300
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 1.8507088422775269,
      "learning_rate": 4.6847847847847845e-05,
      "loss": 1.175,
      "mean_token_accuracy": 0.6871194171905518,
      "num_tokens": 6726715.0,
      "step": 6400
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 1.8633077144622803,
      "learning_rate": 4.67977977977978e-05,
      "loss": 1.1628,
      "mean_token_accuracy": 0.6901582609117031,
      "num_tokens": 6831437.0,
      "step": 6500
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 1.8423494100570679,
      "learning_rate": 4.674774774774775e-05,
      "loss": 1.1678,
      "mean_token_accuracy": 0.6863302068412304,
      "num_tokens": 6937712.0,
      "step": 6600
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 2.2213823795318604,
      "learning_rate": 4.66976976976977e-05,
      "loss": 1.1619,
      "mean_token_accuracy": 0.6899043872952462,
      "num_tokens": 7043315.0,
      "step": 6700
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 1.6515417098999023,
      "learning_rate": 4.664764764764765e-05,
      "loss": 1.1657,
      "mean_token_accuracy": 0.6872644770145416,
      "num_tokens": 7148952.0,
      "step": 6800
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 1.6944139003753662,
      "learning_rate": 4.6597597597597595e-05,
      "loss": 1.1594,
      "mean_token_accuracy": 0.6874394477903842,
      "num_tokens": 7254235.0,
      "step": 6900
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 1.9043890237808228,
      "learning_rate": 4.654754754754755e-05,
      "loss": 1.1556,
      "mean_token_accuracy": 0.691826983988285,
      "num_tokens": 7359494.0,
      "step": 7000
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 1.728797435760498,
      "learning_rate": 4.64974974974975e-05,
      "loss": 1.1642,
      "mean_token_accuracy": 0.6873422528803349,
      "num_tokens": 7464460.0,
      "step": 7100
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9609899520874023,
      "learning_rate": 4.644744744744745e-05,
      "loss": 1.1465,
      "mean_token_accuracy": 0.691022374033928,
      "num_tokens": 7567503.0,
      "step": 7200
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 1.8544446229934692,
      "learning_rate": 4.63973973973974e-05,
      "loss": 1.1601,
      "mean_token_accuracy": 0.6890944221615791,
      "num_tokens": 7672628.0,
      "step": 7300
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 1.9247897863388062,
      "learning_rate": 4.6347347347347345e-05,
      "loss": 1.1556,
      "mean_token_accuracy": 0.6896175119280815,
      "num_tokens": 7776624.0,
      "step": 7400
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.6295627355575562,
      "learning_rate": 4.6297297297297295e-05,
      "loss": 1.1513,
      "mean_token_accuracy": 0.6900931291282177,
      "num_tokens": 7882726.0,
      "step": 7500
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 1.7041486501693726,
      "learning_rate": 4.624724724724725e-05,
      "loss": 1.1539,
      "mean_token_accuracy": 0.6908086994290352,
      "num_tokens": 7987417.0,
      "step": 7600
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 1.746031403541565,
      "learning_rate": 4.61971971971972e-05,
      "loss": 1.1533,
      "mean_token_accuracy": 0.6902407252788544,
      "num_tokens": 8092800.0,
      "step": 7700
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 1.559646487236023,
      "learning_rate": 4.614714714714715e-05,
      "loss": 1.1724,
      "mean_token_accuracy": 0.6853185524046421,
      "num_tokens": 8198016.0,
      "step": 7800
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 1.881356120109558,
      "learning_rate": 4.6097097097097096e-05,
      "loss": 1.1445,
      "mean_token_accuracy": 0.6902015233039855,
      "num_tokens": 8301511.0,
      "step": 7900
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 2.0011518001556396,
      "learning_rate": 4.6047047047047046e-05,
      "loss": 1.1529,
      "mean_token_accuracy": 0.6907704950869084,
      "num_tokens": 8406888.0,
      "step": 8000
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8615013360977173,
      "learning_rate": 4.5996996996997e-05,
      "loss": 1.14,
      "mean_token_accuracy": 0.6935136184096337,
      "num_tokens": 8512538.0,
      "step": 8100
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 1.6370810270309448,
      "learning_rate": 4.594694694694695e-05,
      "loss": 1.1621,
      "mean_token_accuracy": 0.6872762104868889,
      "num_tokens": 8617673.0,
      "step": 8200
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 1.6580482721328735,
      "learning_rate": 4.5897397397397403e-05,
      "loss": 1.1343,
      "mean_token_accuracy": 0.6944273139536381,
      "num_tokens": 8721069.0,
      "step": 8300
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 1.7879680395126343,
      "learning_rate": 4.584734734734735e-05,
      "loss": 1.1425,
      "mean_token_accuracy": 0.6924053314328193,
      "num_tokens": 8825476.0,
      "step": 8400
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 1.7699384689331055,
      "learning_rate": 4.57972972972973e-05,
      "loss": 1.1466,
      "mean_token_accuracy": 0.69018508836627,
      "num_tokens": 8928194.0,
      "step": 8500
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 1.602425217628479,
      "learning_rate": 4.574724724724725e-05,
      "loss": 1.1477,
      "mean_token_accuracy": 0.6920514740049839,
      "num_tokens": 9034102.0,
      "step": 8600
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 1.9168188571929932,
      "learning_rate": 4.56971971971972e-05,
      "loss": 1.1506,
      "mean_token_accuracy": 0.6904843083024025,
      "num_tokens": 9138856.0,
      "step": 8700
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 1.7294131517410278,
      "learning_rate": 4.5647647647647654e-05,
      "loss": 1.1512,
      "mean_token_accuracy": 0.6913047986477614,
      "num_tokens": 9243176.0,
      "step": 8800
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 1.9190598726272583,
      "learning_rate": 4.5597597597597605e-05,
      "loss": 1.1556,
      "mean_token_accuracy": 0.6898306562006473,
      "num_tokens": 9348793.0,
      "step": 8900
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.962465524673462,
      "learning_rate": 4.554754754754755e-05,
      "loss": 1.1439,
      "mean_token_accuracy": 0.6913298784196377,
      "num_tokens": 9451915.0,
      "step": 9000
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 1.8304656744003296,
      "learning_rate": 4.54974974974975e-05,
      "loss": 1.1416,
      "mean_token_accuracy": 0.692226559817791,
      "num_tokens": 9557019.0,
      "step": 9100
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 1.6827925443649292,
      "learning_rate": 4.544744744744745e-05,
      "loss": 1.139,
      "mean_token_accuracy": 0.6936572295427322,
      "num_tokens": 9660601.0,
      "step": 9200
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 1.7376519441604614,
      "learning_rate": 4.53973973973974e-05,
      "loss": 1.1478,
      "mean_token_accuracy": 0.6932355047762394,
      "num_tokens": 9767216.0,
      "step": 9300
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 1.7094987630844116,
      "learning_rate": 4.5347347347347355e-05,
      "loss": 1.1422,
      "mean_token_accuracy": 0.6935181717574597,
      "num_tokens": 9871890.0,
      "step": 9400
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 1.5313045978546143,
      "learning_rate": 4.52972972972973e-05,
      "loss": 1.1361,
      "mean_token_accuracy": 0.6923998729884624,
      "num_tokens": 9976445.0,
      "step": 9500
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.9337416887283325,
      "learning_rate": 4.524724724724725e-05,
      "loss": 1.1615,
      "mean_token_accuracy": 0.6883316569030284,
      "num_tokens": 10082389.0,
      "step": 9600
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 1.8728322982788086,
      "learning_rate": 4.51971971971972e-05,
      "loss": 1.1645,
      "mean_token_accuracy": 0.6904284483194352,
      "num_tokens": 10188061.0,
      "step": 9700
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 1.6816338300704956,
      "learning_rate": 4.514714714714715e-05,
      "loss": 1.155,
      "mean_token_accuracy": 0.6891573397815227,
      "num_tokens": 10294201.0,
      "step": 9800
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7388113737106323,
      "learning_rate": 4.50970970970971e-05,
      "loss": 1.1424,
      "mean_token_accuracy": 0.6945464704930783,
      "num_tokens": 10398211.0,
      "step": 9900
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 2.017439126968384,
      "learning_rate": 4.504704704704705e-05,
      "loss": 1.1618,
      "mean_token_accuracy": 0.6897443530708551,
      "num_tokens": 10503574.0,
      "step": 10000
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 1.6874185800552368,
      "learning_rate": 4.4996996996997e-05,
      "loss": 1.1491,
      "mean_token_accuracy": 0.6918561545014381,
      "num_tokens": 10609109.0,
      "step": 10100
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.6375970840454102,
      "learning_rate": 4.494694694694695e-05,
      "loss": 1.1401,
      "mean_token_accuracy": 0.694717214256525,
      "num_tokens": 10711941.0,
      "step": 10200
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 1.8037587404251099,
      "learning_rate": 4.48968968968969e-05,
      "loss": 1.1582,
      "mean_token_accuracy": 0.6898087671399117,
      "num_tokens": 10816102.0,
      "step": 10300
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 1.6055353879928589,
      "learning_rate": 4.484684684684685e-05,
      "loss": 1.1497,
      "mean_token_accuracy": 0.6922832942008972,
      "num_tokens": 10921477.0,
      "step": 10400
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 1.6564985513687134,
      "learning_rate": 4.47967967967968e-05,
      "loss": 1.1419,
      "mean_token_accuracy": 0.6936670482158661,
      "num_tokens": 11026233.0,
      "step": 10500
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 2.1297078132629395,
      "learning_rate": 4.474674674674675e-05,
      "loss": 1.1412,
      "mean_token_accuracy": 0.6914750050008297,
      "num_tokens": 11130335.0,
      "step": 10600
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 1.8514684438705444,
      "learning_rate": 4.46966966966967e-05,
      "loss": 1.1506,
      "mean_token_accuracy": 0.692382256090641,
      "num_tokens": 11235506.0,
      "step": 10700
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.674277901649475,
      "learning_rate": 4.464664664664665e-05,
      "loss": 1.1373,
      "mean_token_accuracy": 0.6929220731556416,
      "num_tokens": 11340915.0,
      "step": 10800
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 1.7511065006256104,
      "learning_rate": 4.45970970970971e-05,
      "loss": 1.1537,
      "mean_token_accuracy": 0.6913883997499943,
      "num_tokens": 11446834.0,
      "step": 10900
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 1.879014253616333,
      "learning_rate": 4.454704704704705e-05,
      "loss": 1.1409,
      "mean_token_accuracy": 0.6922766636312008,
      "num_tokens": 11552073.0,
      "step": 11000
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 1.9234882593154907,
      "learning_rate": 4.4496996996997e-05,
      "loss": 1.1455,
      "mean_token_accuracy": 0.6925714791566133,
      "num_tokens": 11658992.0,
      "step": 11100
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 1.726840615272522,
      "learning_rate": 4.444694694694695e-05,
      "loss": 1.1466,
      "mean_token_accuracy": 0.6910365802049637,
      "num_tokens": 11764480.0,
      "step": 11200
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 1.6943010091781616,
      "learning_rate": 4.43968968968969e-05,
      "loss": 1.1331,
      "mean_token_accuracy": 0.6960535421967506,
      "num_tokens": 11868238.0,
      "step": 11300
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.8438304662704468,
      "learning_rate": 4.434684684684685e-05,
      "loss": 1.1458,
      "mean_token_accuracy": 0.6918225353211165,
      "num_tokens": 11973577.0,
      "step": 11400
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 1.6491084098815918,
      "learning_rate": 4.4296796796796794e-05,
      "loss": 1.162,
      "mean_token_accuracy": 0.6893159203976392,
      "num_tokens": 12079157.0,
      "step": 11500
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 1.665108561515808,
      "learning_rate": 4.424674674674675e-05,
      "loss": 1.1339,
      "mean_token_accuracy": 0.693563023507595,
      "num_tokens": 12183754.0,
      "step": 11600
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.884604573249817,
      "learning_rate": 4.41966966966967e-05,
      "loss": 1.1378,
      "mean_token_accuracy": 0.6936463825404644,
      "num_tokens": 12287978.0,
      "step": 11700
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 1.7551664113998413,
      "learning_rate": 4.414664664664665e-05,
      "loss": 1.1356,
      "mean_token_accuracy": 0.6935402861237526,
      "num_tokens": 12392227.0,
      "step": 11800
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 1.8554130792617798,
      "learning_rate": 4.40965965965966e-05,
      "loss": 1.1448,
      "mean_token_accuracy": 0.6923294246196747,
      "num_tokens": 12496554.0,
      "step": 11900
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.6649245023727417,
      "learning_rate": 4.4046546546546544e-05,
      "loss": 1.1336,
      "mean_token_accuracy": 0.6951658552139998,
      "num_tokens": 12601191.0,
      "step": 12000
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 1.7145494222640991,
      "learning_rate": 4.39964964964965e-05,
      "loss": 1.162,
      "mean_token_accuracy": 0.6897752460092306,
      "num_tokens": 12707866.0,
      "step": 12100
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 1.7305668592453003,
      "learning_rate": 4.394644644644645e-05,
      "loss": 1.1375,
      "mean_token_accuracy": 0.6943505974113942,
      "num_tokens": 12811048.0,
      "step": 12200
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 1.8568955659866333,
      "learning_rate": 4.38963963963964e-05,
      "loss": 1.1262,
      "mean_token_accuracy": 0.695238381177187,
      "num_tokens": 12914858.0,
      "step": 12300
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 1.7192143201828003,
      "learning_rate": 4.384634634634635e-05,
      "loss": 1.1361,
      "mean_token_accuracy": 0.6934277351200581,
      "num_tokens": 13019195.0,
      "step": 12400
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.6596832275390625,
      "learning_rate": 4.3796296296296294e-05,
      "loss": 1.1293,
      "mean_token_accuracy": 0.6951425203680992,
      "num_tokens": 13123122.0,
      "step": 12500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7220830917358398,
      "learning_rate": 4.3746246246246244e-05,
      "loss": 1.1276,
      "mean_token_accuracy": 0.6956617401540279,
      "num_tokens": 13227898.0,
      "step": 12600
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 1.885026454925537,
      "learning_rate": 4.36961961961962e-05,
      "loss": 1.1394,
      "mean_token_accuracy": 0.6923844593763352,
      "num_tokens": 13331951.0,
      "step": 12700
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 1.6145111322402954,
      "learning_rate": 4.364614614614615e-05,
      "loss": 1.1449,
      "mean_token_accuracy": 0.6928783877938985,
      "num_tokens": 13437980.0,
      "step": 12800
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 1.8154882192611694,
      "learning_rate": 4.35960960960961e-05,
      "loss": 1.1222,
      "mean_token_accuracy": 0.6972254036366939,
      "num_tokens": 13542702.0,
      "step": 12900
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 2.014331579208374,
      "learning_rate": 4.3546046046046045e-05,
      "loss": 1.1309,
      "mean_token_accuracy": 0.6937360993027687,
      "num_tokens": 13646080.0,
      "step": 13000
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 1.7747715711593628,
      "learning_rate": 4.3495995995995995e-05,
      "loss": 1.1633,
      "mean_token_accuracy": 0.691522763967514,
      "num_tokens": 13752648.0,
      "step": 13100
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.7467790842056274,
      "learning_rate": 4.344594594594595e-05,
      "loss": 1.1233,
      "mean_token_accuracy": 0.6955693727731704,
      "num_tokens": 13857324.0,
      "step": 13200
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 1.4000227451324463,
      "learning_rate": 4.33958958958959e-05,
      "loss": 1.16,
      "mean_token_accuracy": 0.6921079613268375,
      "num_tokens": 13964169.0,
      "step": 13300
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 1.6891621351242065,
      "learning_rate": 4.334584584584585e-05,
      "loss": 1.1275,
      "mean_token_accuracy": 0.6962852261960506,
      "num_tokens": 14067145.0,
      "step": 13400
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5668541193008423,
      "learning_rate": 4.3295795795795795e-05,
      "loss": 1.1361,
      "mean_token_accuracy": 0.693483749628067,
      "num_tokens": 14172443.0,
      "step": 13500
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 1.8983756303787231,
      "learning_rate": 4.3245745745745745e-05,
      "loss": 1.1318,
      "mean_token_accuracy": 0.6960614209622145,
      "num_tokens": 14275560.0,
      "step": 13600
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 1.924152135848999,
      "learning_rate": 4.3195695695695695e-05,
      "loss": 1.1341,
      "mean_token_accuracy": 0.6940994346141816,
      "num_tokens": 14380467.0,
      "step": 13700
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.9610180854797363,
      "learning_rate": 4.314564564564565e-05,
      "loss": 1.1333,
      "mean_token_accuracy": 0.6954520151019097,
      "num_tokens": 14484700.0,
      "step": 13800
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 1.546825647354126,
      "learning_rate": 4.30955955955956e-05,
      "loss": 1.1283,
      "mean_token_accuracy": 0.6963397683203221,
      "num_tokens": 14589801.0,
      "step": 13900
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.6811634302139282,
      "learning_rate": 4.3045545545545545e-05,
      "loss": 1.1416,
      "mean_token_accuracy": 0.6919310817122459,
      "num_tokens": 14694559.0,
      "step": 14000
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 1.9631439447402954,
      "learning_rate": 4.2995495495495495e-05,
      "loss": 1.1443,
      "mean_token_accuracy": 0.6928557701408863,
      "num_tokens": 14799001.0,
      "step": 14100
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 1.7740753889083862,
      "learning_rate": 4.2945445445445445e-05,
      "loss": 1.1364,
      "mean_token_accuracy": 0.6939551541209221,
      "num_tokens": 14905045.0,
      "step": 14200
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 1.7907822132110596,
      "learning_rate": 4.28953953953954e-05,
      "loss": 1.1301,
      "mean_token_accuracy": 0.6963045838475227,
      "num_tokens": 15008196.0,
      "step": 14300
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5436317920684814,
      "learning_rate": 4.284534534534535e-05,
      "loss": 1.1286,
      "mean_token_accuracy": 0.6949174197018146,
      "num_tokens": 15112901.0,
      "step": 14400
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 1.5050228834152222,
      "learning_rate": 4.2795295295295296e-05,
      "loss": 1.1291,
      "mean_token_accuracy": 0.6966951504349709,
      "num_tokens": 15219351.0,
      "step": 14500
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 1.7796522378921509,
      "learning_rate": 4.2745245245245246e-05,
      "loss": 1.137,
      "mean_token_accuracy": 0.6949547498673201,
      "num_tokens": 15325862.0,
      "step": 14600
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 1.6703144311904907,
      "learning_rate": 4.2695195195195196e-05,
      "loss": 1.142,
      "mean_token_accuracy": 0.6936501054465771,
      "num_tokens": 15429916.0,
      "step": 14700
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 1.7596124410629272,
      "learning_rate": 4.2645145145145146e-05,
      "loss": 1.148,
      "mean_token_accuracy": 0.6933142966032029,
      "num_tokens": 15535237.0,
      "step": 14800
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 2.0892410278320312,
      "learning_rate": 4.2595095095095096e-05,
      "loss": 1.1313,
      "mean_token_accuracy": 0.6961278854310513,
      "num_tokens": 15640501.0,
      "step": 14900
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.6990998983383179,
      "learning_rate": 4.2545045045045046e-05,
      "loss": 1.1172,
      "mean_token_accuracy": 0.6981284485757351,
      "num_tokens": 15744119.0,
      "step": 15000
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 1.7056776285171509,
      "learning_rate": 4.24954954954955e-05,
      "loss": 1.1341,
      "mean_token_accuracy": 0.6942026077210903,
      "num_tokens": 15849819.0,
      "step": 15100
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 1.5587985515594482,
      "learning_rate": 4.244544544544545e-05,
      "loss": 1.1348,
      "mean_token_accuracy": 0.6929332610964775,
      "num_tokens": 15953674.0,
      "step": 15200
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8521907329559326,
      "learning_rate": 4.23953953953954e-05,
      "loss": 1.1198,
      "mean_token_accuracy": 0.6970074243843556,
      "num_tokens": 16058220.0,
      "step": 15300
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 1.6310210227966309,
      "learning_rate": 4.234534534534535e-05,
      "loss": 1.1207,
      "mean_token_accuracy": 0.6970750875771046,
      "num_tokens": 16162668.0,
      "step": 15400
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 1.84062659740448,
      "learning_rate": 4.22952952952953e-05,
      "loss": 1.135,
      "mean_token_accuracy": 0.6929803429543973,
      "num_tokens": 16266701.0,
      "step": 15500
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.6775001287460327,
      "learning_rate": 4.224524524524525e-05,
      "loss": 1.1239,
      "mean_token_accuracy": 0.6954423347860574,
      "num_tokens": 16371550.0,
      "step": 15600
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 1.63795804977417,
      "learning_rate": 4.21951951951952e-05,
      "loss": 1.1174,
      "mean_token_accuracy": 0.6975146152079106,
      "num_tokens": 16475164.0,
      "step": 15700
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 1.739820957183838,
      "learning_rate": 4.214564564564565e-05,
      "loss": 1.1315,
      "mean_token_accuracy": 0.6945417156815529,
      "num_tokens": 16580155.0,
      "step": 15800
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 1.836627721786499,
      "learning_rate": 4.20955955955956e-05,
      "loss": 1.1215,
      "mean_token_accuracy": 0.697511439025402,
      "num_tokens": 16683016.0,
      "step": 15900
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.8795688152313232,
      "learning_rate": 4.204554554554555e-05,
      "loss": 1.1454,
      "mean_token_accuracy": 0.6937532521784305,
      "num_tokens": 16788197.0,
      "step": 16000
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 1.7362143993377686,
      "learning_rate": 4.19954954954955e-05,
      "loss": 1.1279,
      "mean_token_accuracy": 0.6953567092120647,
      "num_tokens": 16894390.0,
      "step": 16100
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6305983066558838,
      "learning_rate": 4.194544544544545e-05,
      "loss": 1.1402,
      "mean_token_accuracy": 0.693119149953127,
      "num_tokens": 16999453.0,
      "step": 16200
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 1.6491557359695435,
      "learning_rate": 4.18953953953954e-05,
      "loss": 1.1289,
      "mean_token_accuracy": 0.6952319909632206,
      "num_tokens": 17103955.0,
      "step": 16300
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 1.5642772912979126,
      "learning_rate": 4.184534534534535e-05,
      "loss": 1.1238,
      "mean_token_accuracy": 0.6966633550822735,
      "num_tokens": 17207908.0,
      "step": 16400
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 1.6777516603469849,
      "learning_rate": 4.179529529529529e-05,
      "loss": 1.1184,
      "mean_token_accuracy": 0.6977918210625649,
      "num_tokens": 17312287.0,
      "step": 16500
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 1.7819162607192993,
      "learning_rate": 4.174524524524525e-05,
      "loss": 1.1422,
      "mean_token_accuracy": 0.694361976981163,
      "num_tokens": 17417052.0,
      "step": 16600
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 1.6224384307861328,
      "learning_rate": 4.16951951951952e-05,
      "loss": 1.1249,
      "mean_token_accuracy": 0.6970640893280506,
      "num_tokens": 17521072.0,
      "step": 16700
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.7478078603744507,
      "learning_rate": 4.164514514514515e-05,
      "loss": 1.1411,
      "mean_token_accuracy": 0.6924894021451473,
      "num_tokens": 17625106.0,
      "step": 16800
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 2.0979738235473633,
      "learning_rate": 4.15950950950951e-05,
      "loss": 1.1044,
      "mean_token_accuracy": 0.7001096031069756,
      "num_tokens": 17727386.0,
      "step": 16900
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 1.6834050416946411,
      "learning_rate": 4.154504504504504e-05,
      "loss": 1.124,
      "mean_token_accuracy": 0.6970853485167027,
      "num_tokens": 17831725.0,
      "step": 17000
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8872145414352417,
      "learning_rate": 4.1494994994995e-05,
      "loss": 1.1239,
      "mean_token_accuracy": 0.6950480504333973,
      "num_tokens": 17936750.0,
      "step": 17100
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 1.6447539329528809,
      "learning_rate": 4.144494494494495e-05,
      "loss": 1.1336,
      "mean_token_accuracy": 0.6933528765290976,
      "num_tokens": 18042211.0,
      "step": 17200
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 1.8004872798919678,
      "learning_rate": 4.13948948948949e-05,
      "loss": 1.1312,
      "mean_token_accuracy": 0.6954559633135795,
      "num_tokens": 18145200.0,
      "step": 17300
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 1.400860071182251,
      "learning_rate": 4.134484484484485e-05,
      "loss": 1.153,
      "mean_token_accuracy": 0.6923310951143503,
      "num_tokens": 18250096.0,
      "step": 17400
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 1.6527358293533325,
      "learning_rate": 4.129479479479479e-05,
      "loss": 1.1096,
      "mean_token_accuracy": 0.6981031604111194,
      "num_tokens": 18354548.0,
      "step": 17500
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 1.7526218891143799,
      "learning_rate": 4.124474474474474e-05,
      "loss": 1.1178,
      "mean_token_accuracy": 0.6962133131921291,
      "num_tokens": 18457951.0,
      "step": 17600
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 1.6007215976715088,
      "learning_rate": 4.11946946946947e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6988142856955528,
      "num_tokens": 18562393.0,
      "step": 17700
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 1.5913183689117432,
      "learning_rate": 4.114464464464465e-05,
      "loss": 1.1285,
      "mean_token_accuracy": 0.6951864869892597,
      "num_tokens": 18669095.0,
      "step": 17800
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 1.6922990083694458,
      "learning_rate": 4.10945945945946e-05,
      "loss": 1.1086,
      "mean_token_accuracy": 0.6993813706934452,
      "num_tokens": 18773252.0,
      "step": 17900
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7690166234970093,
      "learning_rate": 4.104454454454454e-05,
      "loss": 1.113,
      "mean_token_accuracy": 0.6996578787267208,
      "num_tokens": 18877833.0,
      "step": 18000
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 1.5762789249420166,
      "learning_rate": 4.099449449449449e-05,
      "loss": 1.1253,
      "mean_token_accuracy": 0.6962596979737282,
      "num_tokens": 18983857.0,
      "step": 18100
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 1.7802752256393433,
      "learning_rate": 4.094444444444445e-05,
      "loss": 1.1278,
      "mean_token_accuracy": 0.6933072201907635,
      "num_tokens": 19087765.0,
      "step": 18200
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 1.7284384965896606,
      "learning_rate": 4.08943943943944e-05,
      "loss": 1.118,
      "mean_token_accuracy": 0.6977024187147617,
      "num_tokens": 19193813.0,
      "step": 18300
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 1.533896803855896,
      "learning_rate": 4.084434434434435e-05,
      "loss": 1.1206,
      "mean_token_accuracy": 0.6965228576958179,
      "num_tokens": 19297355.0,
      "step": 18400
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.543357491493225,
      "learning_rate": 4.07947947947948e-05,
      "loss": 1.1071,
      "mean_token_accuracy": 0.7013824343681335,
      "num_tokens": 19401818.0,
      "step": 18500
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 1.7607983350753784,
      "learning_rate": 4.0744744744744744e-05,
      "loss": 1.1272,
      "mean_token_accuracy": 0.6960887776315212,
      "num_tokens": 19507511.0,
      "step": 18600
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 1.8779817819595337,
      "learning_rate": 4.0694694694694694e-05,
      "loss": 1.1259,
      "mean_token_accuracy": 0.695450888723135,
      "num_tokens": 19612153.0,
      "step": 18700
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 1.60438871383667,
      "learning_rate": 4.0644644644644644e-05,
      "loss": 1.1105,
      "mean_token_accuracy": 0.6990455478429795,
      "num_tokens": 19717034.0,
      "step": 18800
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7001327276229858,
      "learning_rate": 4.05945945945946e-05,
      "loss": 1.1394,
      "mean_token_accuracy": 0.6937132549285888,
      "num_tokens": 19823342.0,
      "step": 18900
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 1.8676166534423828,
      "learning_rate": 4.0544544544544544e-05,
      "loss": 1.1038,
      "mean_token_accuracy": 0.7000733231008053,
      "num_tokens": 19926299.0,
      "step": 19000
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 1.8582594394683838,
      "learning_rate": 4.0494494494494494e-05,
      "loss": 1.1247,
      "mean_token_accuracy": 0.6971198329329491,
      "num_tokens": 20032663.0,
      "step": 19100
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 1.832120418548584,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 1.1313,
      "mean_token_accuracy": 0.6933822758495808,
      "num_tokens": 20137296.0,
      "step": 19200
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 1.6938658952713013,
      "learning_rate": 4.0394394394394394e-05,
      "loss": 1.1233,
      "mean_token_accuracy": 0.6956917060911656,
      "num_tokens": 20242880.0,
      "step": 19300
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 1.7010250091552734,
      "learning_rate": 4.034434434434435e-05,
      "loss": 1.1349,
      "mean_token_accuracy": 0.6943548412621021,
      "num_tokens": 20346973.0,
      "step": 19400
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 1.5746419429779053,
      "learning_rate": 4.0294294294294294e-05,
      "loss": 1.1185,
      "mean_token_accuracy": 0.6964694658666849,
      "num_tokens": 20451932.0,
      "step": 19500
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 1.679559350013733,
      "learning_rate": 4.0244244244244244e-05,
      "loss": 1.1235,
      "mean_token_accuracy": 0.6976062034070492,
      "num_tokens": 20557341.0,
      "step": 19600
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 1.9840335845947266,
      "learning_rate": 4.0194194194194195e-05,
      "loss": 1.1324,
      "mean_token_accuracy": 0.6947835654020309,
      "num_tokens": 20661652.0,
      "step": 19700
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8139424324035645,
      "learning_rate": 4.0144144144144145e-05,
      "loss": 1.1185,
      "mean_token_accuracy": 0.6974386216700077,
      "num_tokens": 20767005.0,
      "step": 19800
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 1.6745762825012207,
      "learning_rate": 4.0094094094094095e-05,
      "loss": 1.1321,
      "mean_token_accuracy": 0.6969481039792299,
      "num_tokens": 20872052.0,
      "step": 19900
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.6610877513885498,
      "learning_rate": 4.0044044044044045e-05,
      "loss": 1.1089,
      "mean_token_accuracy": 0.6985660521686077,
      "num_tokens": 20976105.0,
      "step": 20000
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 1.8795678615570068,
      "learning_rate": 3.9993993993993995e-05,
      "loss": 1.1283,
      "mean_token_accuracy": 0.695343074798584,
      "num_tokens": 21081822.0,
      "step": 20100
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 1.9232193231582642,
      "learning_rate": 3.9943943943943945e-05,
      "loss": 1.123,
      "mean_token_accuracy": 0.6974026583135128,
      "num_tokens": 21187489.0,
      "step": 20200
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 1.845517873764038,
      "learning_rate": 3.9893893893893895e-05,
      "loss": 1.1183,
      "mean_token_accuracy": 0.6954982563853264,
      "num_tokens": 21292554.0,
      "step": 20300
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 1.7206547260284424,
      "learning_rate": 3.9843843843843845e-05,
      "loss": 1.1176,
      "mean_token_accuracy": 0.6978555296361446,
      "num_tokens": 21398247.0,
      "step": 20400
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 1.6970317363739014,
      "learning_rate": 3.9793793793793795e-05,
      "loss": 1.1257,
      "mean_token_accuracy": 0.6954311533272266,
      "num_tokens": 21503115.0,
      "step": 20500
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 1.7497481107711792,
      "learning_rate": 3.9743743743743745e-05,
      "loss": 1.1328,
      "mean_token_accuracy": 0.6932846845686436,
      "num_tokens": 21607542.0,
      "step": 20600
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6772332191467285,
      "learning_rate": 3.9693693693693695e-05,
      "loss": 1.1411,
      "mean_token_accuracy": 0.6922699070721865,
      "num_tokens": 21713124.0,
      "step": 20700
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 1.7692068815231323,
      "learning_rate": 3.9643643643643645e-05,
      "loss": 1.1299,
      "mean_token_accuracy": 0.6960664935410023,
      "num_tokens": 21819874.0,
      "step": 20800
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 1.7003830671310425,
      "learning_rate": 3.9593593593593595e-05,
      "loss": 1.1302,
      "mean_token_accuracy": 0.696288733035326,
      "num_tokens": 21926018.0,
      "step": 20900
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.5392283201217651,
      "learning_rate": 3.9543543543543545e-05,
      "loss": 1.1118,
      "mean_token_accuracy": 0.6972425217926502,
      "num_tokens": 22031811.0,
      "step": 21000
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 1.5361206531524658,
      "learning_rate": 3.9493993993993996e-05,
      "loss": 1.1371,
      "mean_token_accuracy": 0.6958124231547117,
      "num_tokens": 22138696.0,
      "step": 21100
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 1.6721069812774658,
      "learning_rate": 3.9443943943943946e-05,
      "loss": 1.1131,
      "mean_token_accuracy": 0.6980795855820179,
      "num_tokens": 22242437.0,
      "step": 21200
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 1.697160243988037,
      "learning_rate": 3.9393893893893896e-05,
      "loss": 1.1158,
      "mean_token_accuracy": 0.6985488165915013,
      "num_tokens": 22347917.0,
      "step": 21300
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 1.7590640783309937,
      "learning_rate": 3.9343843843843846e-05,
      "loss": 1.1148,
      "mean_token_accuracy": 0.6999427878856659,
      "num_tokens": 22454811.0,
      "step": 21400
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 1.8577051162719727,
      "learning_rate": 3.9293793793793797e-05,
      "loss": 1.1135,
      "mean_token_accuracy": 0.6974944993853569,
      "num_tokens": 22558847.0,
      "step": 21500
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6497995853424072,
      "learning_rate": 3.9243743743743747e-05,
      "loss": 1.1147,
      "mean_token_accuracy": 0.6980917172133922,
      "num_tokens": 22663151.0,
      "step": 21600
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 1.8886457681655884,
      "learning_rate": 3.91936936936937e-05,
      "loss": 1.1261,
      "mean_token_accuracy": 0.6942895843833685,
      "num_tokens": 22768851.0,
      "step": 21700
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 1.538605809211731,
      "learning_rate": 3.914364364364365e-05,
      "loss": 1.113,
      "mean_token_accuracy": 0.6992757526785135,
      "num_tokens": 22874148.0,
      "step": 21800
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 1.9222817420959473,
      "learning_rate": 3.90935935935936e-05,
      "loss": 1.1256,
      "mean_token_accuracy": 0.6954681214690208,
      "num_tokens": 22978836.0,
      "step": 21900
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.8569740056991577,
      "learning_rate": 3.904354354354355e-05,
      "loss": 1.1242,
      "mean_token_accuracy": 0.6961892645061016,
      "num_tokens": 23085338.0,
      "step": 22000
    },
    {
      "epoch": 0.9822222222222222,
      "grad_norm": 1.6471657752990723,
      "learning_rate": 3.89934934934935e-05,
      "loss": 1.1142,
      "mean_token_accuracy": 0.6977016746997833,
      "num_tokens": 23189019.0,
      "step": 22100
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 1.6156281232833862,
      "learning_rate": 3.894344344344345e-05,
      "loss": 1.1338,
      "mean_token_accuracy": 0.6957700063288211,
      "num_tokens": 23293152.0,
      "step": 22200
    },
    {
      "epoch": 0.9911111111111112,
      "grad_norm": 1.6914029121398926,
      "learning_rate": 3.88933933933934e-05,
      "loss": 1.1161,
      "mean_token_accuracy": 0.6972967691719532,
      "num_tokens": 23397290.0,
      "step": 22300
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 1.6147209405899048,
      "learning_rate": 3.884334334334335e-05,
      "loss": 1.13,
      "mean_token_accuracy": 0.6985813444852829,
      "num_tokens": 23502231.0,
      "step": 22400
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7290289402008057,
      "learning_rate": 3.879329329329329e-05,
      "loss": 1.1245,
      "mean_token_accuracy": 0.6955421651899815,
      "num_tokens": 23606209.0,
      "step": 22500
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 1.6686766147613525,
      "learning_rate": 3.874324324324324e-05,
      "loss": 1.1188,
      "mean_token_accuracy": 0.6967158018052578,
      "num_tokens": 23711725.0,
      "step": 22600
    },
    {
      "epoch": 1.008888888888889,
      "grad_norm": 1.6901097297668457,
      "learning_rate": 3.86931931931932e-05,
      "loss": 1.1172,
      "mean_token_accuracy": 0.6982336628437043,
      "num_tokens": 23815224.0,
      "step": 22700
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.639870047569275,
      "learning_rate": 3.864314314314315e-05,
      "loss": 1.1132,
      "mean_token_accuracy": 0.6982314202189446,
      "num_tokens": 23920413.0,
      "step": 22800
    },
    {
      "epoch": 1.0177777777777777,
      "grad_norm": 2.0133092403411865,
      "learning_rate": 3.85930930930931e-05,
      "loss": 1.1248,
      "mean_token_accuracy": 0.6973735641688108,
      "num_tokens": 24026537.0,
      "step": 22900
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 1.681373953819275,
      "learning_rate": 3.854304304304304e-05,
      "loss": 1.1166,
      "mean_token_accuracy": 0.6971783943474292,
      "num_tokens": 24131560.0,
      "step": 23000
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 1.5212599039077759,
      "learning_rate": 3.849299299299299e-05,
      "loss": 1.134,
      "mean_token_accuracy": 0.6955734923481941,
      "num_tokens": 24237811.0,
      "step": 23100
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 2.066070556640625,
      "learning_rate": 3.844294294294295e-05,
      "loss": 1.119,
      "mean_token_accuracy": 0.6971976048499345,
      "num_tokens": 24343530.0,
      "step": 23200
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 1.7184295654296875,
      "learning_rate": 3.83928928928929e-05,
      "loss": 1.1284,
      "mean_token_accuracy": 0.694656780809164,
      "num_tokens": 24450400.0,
      "step": 23300
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.6122204065322876,
      "learning_rate": 3.834284284284285e-05,
      "loss": 1.1234,
      "mean_token_accuracy": 0.6987206267565489,
      "num_tokens": 24556038.0,
      "step": 23400
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 1.3688045740127563,
      "learning_rate": 3.829279279279279e-05,
      "loss": 1.1207,
      "mean_token_accuracy": 0.6971863344311714,
      "num_tokens": 24660680.0,
      "step": 23500
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 1.650193452835083,
      "learning_rate": 3.824274274274274e-05,
      "loss": 1.1227,
      "mean_token_accuracy": 0.6972111666947604,
      "num_tokens": 24765780.0,
      "step": 23600
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 1.7084643840789795,
      "learning_rate": 3.819269269269269e-05,
      "loss": 1.1143,
      "mean_token_accuracy": 0.7003848198801279,
      "num_tokens": 24870779.0,
      "step": 23700
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 1.742864966392517,
      "learning_rate": 3.814264264264265e-05,
      "loss": 1.1182,
      "mean_token_accuracy": 0.6983627434819937,
      "num_tokens": 24975786.0,
      "step": 23800
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 1.6816736459732056,
      "learning_rate": 3.80925925925926e-05,
      "loss": 1.109,
      "mean_token_accuracy": 0.6979360856115818,
      "num_tokens": 25080279.0,
      "step": 23900
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.5613495111465454,
      "learning_rate": 3.804254254254254e-05,
      "loss": 1.1135,
      "mean_token_accuracy": 0.6981831237673759,
      "num_tokens": 25184527.0,
      "step": 24000
    },
    {
      "epoch": 1.0711111111111111,
      "grad_norm": 1.492478609085083,
      "learning_rate": 3.799299299299299e-05,
      "loss": 1.1166,
      "mean_token_accuracy": 0.6976764464378357,
      "num_tokens": 25291949.0,
      "step": 24100
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 1.6076456308364868,
      "learning_rate": 3.794294294294294e-05,
      "loss": 1.1251,
      "mean_token_accuracy": 0.696288368999958,
      "num_tokens": 25396677.0,
      "step": 24200
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.783028483390808,
      "learning_rate": 3.789289289289289e-05,
      "loss": 1.1039,
      "mean_token_accuracy": 0.7011517353355885,
      "num_tokens": 25501297.0,
      "step": 24300
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 1.586665153503418,
      "learning_rate": 3.784284284284285e-05,
      "loss": 1.1062,
      "mean_token_accuracy": 0.6993644890189171,
      "num_tokens": 25605077.0,
      "step": 24400
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 1.3591954708099365,
      "learning_rate": 3.77927927927928e-05,
      "loss": 1.1106,
      "mean_token_accuracy": 0.6991433575749397,
      "num_tokens": 25710224.0,
      "step": 24500
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 1.6653814315795898,
      "learning_rate": 3.774274274274274e-05,
      "loss": 1.1157,
      "mean_token_accuracy": 0.7008020933717489,
      "num_tokens": 25815544.0,
      "step": 24600
    },
    {
      "epoch": 1.0977777777777777,
      "grad_norm": 1.7370214462280273,
      "learning_rate": 3.769269269269269e-05,
      "loss": 1.1183,
      "mean_token_accuracy": 0.6971335909515619,
      "num_tokens": 25920402.0,
      "step": 24700
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 1.7442436218261719,
      "learning_rate": 3.764264264264264e-05,
      "loss": 1.125,
      "mean_token_accuracy": 0.696819472014904,
      "num_tokens": 26024662.0,
      "step": 24800
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 1.4459342956542969,
      "learning_rate": 3.759259259259259e-05,
      "loss": 1.1101,
      "mean_token_accuracy": 0.6999624739587307,
      "num_tokens": 26130689.0,
      "step": 24900
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.649880051612854,
      "learning_rate": 3.754254254254255e-05,
      "loss": 1.1085,
      "mean_token_accuracy": 0.7010215071588755,
      "num_tokens": 26235895.0,
      "step": 25000
    },
    {
      "epoch": 1.1155555555555556,
      "grad_norm": 1.7869343757629395,
      "learning_rate": 3.749249249249249e-05,
      "loss": 1.1102,
      "mean_token_accuracy": 0.6980751153826713,
      "num_tokens": 26339697.0,
      "step": 25100
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7073053121566772,
      "learning_rate": 3.744244244244244e-05,
      "loss": 1.1298,
      "mean_token_accuracy": 0.6975151616334915,
      "num_tokens": 26446168.0,
      "step": 25200
    },
    {
      "epoch": 1.1244444444444444,
      "grad_norm": 1.6064623594284058,
      "learning_rate": 3.739239239239239e-05,
      "loss": 1.1092,
      "mean_token_accuracy": 0.6996495746076107,
      "num_tokens": 26551782.0,
      "step": 25300
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 1.6138153076171875,
      "learning_rate": 3.734234234234234e-05,
      "loss": 1.1122,
      "mean_token_accuracy": 0.6990244570374489,
      "num_tokens": 26656435.0,
      "step": 25400
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 1.7354165315628052,
      "learning_rate": 3.72922922922923e-05,
      "loss": 1.1167,
      "mean_token_accuracy": 0.69774836525321,
      "num_tokens": 26761855.0,
      "step": 25500
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 2.045854330062866,
      "learning_rate": 3.724224224224224e-05,
      "loss": 1.1171,
      "mean_token_accuracy": 0.6993056483566761,
      "num_tokens": 26868833.0,
      "step": 25600
    },
    {
      "epoch": 1.1422222222222222,
      "grad_norm": 2.0392065048217773,
      "learning_rate": 3.719219219219219e-05,
      "loss": 1.1114,
      "mean_token_accuracy": 0.701122322678566,
      "num_tokens": 26974695.0,
      "step": 25700
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 1.6699681282043457,
      "learning_rate": 3.7142142142142143e-05,
      "loss": 1.0981,
      "mean_token_accuracy": 0.7027058874070644,
      "num_tokens": 27078376.0,
      "step": 25800
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 1.9467253684997559,
      "learning_rate": 3.7092092092092094e-05,
      "loss": 1.1108,
      "mean_token_accuracy": 0.6984983552992344,
      "num_tokens": 27183373.0,
      "step": 25900
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 1.7923579216003418,
      "learning_rate": 3.7042042042042044e-05,
      "loss": 1.1094,
      "mean_token_accuracy": 0.6999124386906623,
      "num_tokens": 27288313.0,
      "step": 26000
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.6243040561676025,
      "learning_rate": 3.6991991991991994e-05,
      "loss": 1.1024,
      "mean_token_accuracy": 0.7003398150205612,
      "num_tokens": 27392409.0,
      "step": 26100
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 1.4900113344192505,
      "learning_rate": 3.6941941941941944e-05,
      "loss": 1.1148,
      "mean_token_accuracy": 0.6991243498027324,
      "num_tokens": 27497349.0,
      "step": 26200
    },
    {
      "epoch": 1.1688888888888889,
      "grad_norm": 1.5822471380233765,
      "learning_rate": 3.6891891891891894e-05,
      "loss": 1.1142,
      "mean_token_accuracy": 0.7005465810000896,
      "num_tokens": 27601185.0,
      "step": 26300
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.668607234954834,
      "learning_rate": 3.6841841841841844e-05,
      "loss": 1.1094,
      "mean_token_accuracy": 0.6994711808115244,
      "num_tokens": 27704873.0,
      "step": 26400
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 1.6973108053207397,
      "learning_rate": 3.6791791791791794e-05,
      "loss": 1.1127,
      "mean_token_accuracy": 0.6979932235181332,
      "num_tokens": 27809931.0,
      "step": 26500
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 1.5961534976959229,
      "learning_rate": 3.6741741741741744e-05,
      "loss": 1.106,
      "mean_token_accuracy": 0.7006593623757362,
      "num_tokens": 27914621.0,
      "step": 26600
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 2.169804096221924,
      "learning_rate": 3.6691691691691694e-05,
      "loss": 1.1262,
      "mean_token_accuracy": 0.6957594869285821,
      "num_tokens": 28020053.0,
      "step": 26700
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 1.6255711317062378,
      "learning_rate": 3.6641641641641644e-05,
      "loss": 1.0955,
      "mean_token_accuracy": 0.7010821339488029,
      "num_tokens": 28124432.0,
      "step": 26800
    },
    {
      "epoch": 1.1955555555555555,
      "grad_norm": 1.578972578048706,
      "learning_rate": 3.6591591591591594e-05,
      "loss": 1.1133,
      "mean_token_accuracy": 0.6983165355026721,
      "num_tokens": 28228912.0,
      "step": 26900
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7156668901443481,
      "learning_rate": 3.6542042042042045e-05,
      "loss": 1.1054,
      "mean_token_accuracy": 0.6980922505259514,
      "num_tokens": 28332753.0,
      "step": 27000
    },
    {
      "epoch": 1.2044444444444444,
      "grad_norm": 1.6609950065612793,
      "learning_rate": 3.6491991991991995e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6991449201107025,
      "num_tokens": 28438016.0,
      "step": 27100
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 1.440289855003357,
      "learning_rate": 3.6441941941941945e-05,
      "loss": 1.0992,
      "mean_token_accuracy": 0.7020045140385628,
      "num_tokens": 28541394.0,
      "step": 27200
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 1.5692206621170044,
      "learning_rate": 3.6391891891891895e-05,
      "loss": 1.095,
      "mean_token_accuracy": 0.7018074984848499,
      "num_tokens": 28646255.0,
      "step": 27300
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 1.7163487672805786,
      "learning_rate": 3.6341841841841845e-05,
      "loss": 1.1073,
      "mean_token_accuracy": 0.700482855886221,
      "num_tokens": 28750416.0,
      "step": 27400
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 1.5809744596481323,
      "learning_rate": 3.6291791791791795e-05,
      "loss": 1.1023,
      "mean_token_accuracy": 0.701277672946453,
      "num_tokens": 28855151.0,
      "step": 27500
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 1.6454334259033203,
      "learning_rate": 3.624174174174174e-05,
      "loss": 1.1172,
      "mean_token_accuracy": 0.7000553092360496,
      "num_tokens": 28961247.0,
      "step": 27600
    },
    {
      "epoch": 1.231111111111111,
      "grad_norm": 1.5252187252044678,
      "learning_rate": 3.6191691691691695e-05,
      "loss": 1.1017,
      "mean_token_accuracy": 0.6995382307469845,
      "num_tokens": 29066395.0,
      "step": 27700
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 1.8297265768051147,
      "learning_rate": 3.6141641641641646e-05,
      "loss": 1.1251,
      "mean_token_accuracy": 0.6983111907541751,
      "num_tokens": 29173167.0,
      "step": 27800
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.6696103811264038,
      "learning_rate": 3.6091591591591596e-05,
      "loss": 1.119,
      "mean_token_accuracy": 0.6994468745589256,
      "num_tokens": 29278307.0,
      "step": 27900
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 1.7125808000564575,
      "learning_rate": 3.6041541541541546e-05,
      "loss": 1.1116,
      "mean_token_accuracy": 0.6998295246064663,
      "num_tokens": 29383414.0,
      "step": 28000
    },
    {
      "epoch": 1.248888888888889,
      "grad_norm": 1.8666386604309082,
      "learning_rate": 3.599149149149149e-05,
      "loss": 1.117,
      "mean_token_accuracy": 0.6970196176320315,
      "num_tokens": 29488786.0,
      "step": 28100
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 1.826817512512207,
      "learning_rate": 3.5941441441441446e-05,
      "loss": 1.1257,
      "mean_token_accuracy": 0.6943378541618586,
      "num_tokens": 29595281.0,
      "step": 28200
    },
    {
      "epoch": 1.2577777777777777,
      "grad_norm": 1.689263105392456,
      "learning_rate": 3.5891391391391396e-05,
      "loss": 1.1143,
      "mean_token_accuracy": 0.6982365630567073,
      "num_tokens": 29701065.0,
      "step": 28300
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 1.8254327774047852,
      "learning_rate": 3.5841341341341346e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6978128391504288,
      "num_tokens": 29806054.0,
      "step": 28400
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 1.6734923124313354,
      "learning_rate": 3.5791291291291296e-05,
      "loss": 1.1043,
      "mean_token_accuracy": 0.6989393991231918,
      "num_tokens": 29909751.0,
      "step": 28500
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 1.4999948740005493,
      "learning_rate": 3.574124124124124e-05,
      "loss": 1.0982,
      "mean_token_accuracy": 0.7021348242461681,
      "num_tokens": 30014500.0,
      "step": 28600
    },
    {
      "epoch": 1.2755555555555556,
      "grad_norm": 1.8608331680297852,
      "learning_rate": 3.569119119119119e-05,
      "loss": 1.1148,
      "mean_token_accuracy": 0.6988101457059384,
      "num_tokens": 30120477.0,
      "step": 28700
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5209144353866577,
      "learning_rate": 3.5641141141141146e-05,
      "loss": 1.0945,
      "mean_token_accuracy": 0.700475212931633,
      "num_tokens": 30224317.0,
      "step": 28800
    },
    {
      "epoch": 1.2844444444444445,
      "grad_norm": 1.767866611480713,
      "learning_rate": 3.5591091091091096e-05,
      "loss": 1.0936,
      "mean_token_accuracy": 0.7012439024448395,
      "num_tokens": 30329719.0,
      "step": 28900
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 1.5195621252059937,
      "learning_rate": 3.5541041041041046e-05,
      "loss": 1.1203,
      "mean_token_accuracy": 0.6977619846165181,
      "num_tokens": 30433222.0,
      "step": 29000
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 1.618795394897461,
      "learning_rate": 3.549099099099099e-05,
      "loss": 1.1088,
      "mean_token_accuracy": 0.7011111243069172,
      "num_tokens": 30536490.0,
      "step": 29100
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 1.6199194192886353,
      "learning_rate": 3.544094094094094e-05,
      "loss": 1.1226,
      "mean_token_accuracy": 0.6970461890846491,
      "num_tokens": 30642233.0,
      "step": 29200
    },
    {
      "epoch": 1.3022222222222222,
      "grad_norm": 1.758629560470581,
      "learning_rate": 3.539089089089089e-05,
      "loss": 1.1064,
      "mean_token_accuracy": 0.6990283493697643,
      "num_tokens": 30745836.0,
      "step": 29300
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 1.7501840591430664,
      "learning_rate": 3.534084084084085e-05,
      "loss": 1.1165,
      "mean_token_accuracy": 0.6971717198193074,
      "num_tokens": 30851439.0,
      "step": 29400
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 1.6514443159103394,
      "learning_rate": 3.529079079079079e-05,
      "loss": 1.1101,
      "mean_token_accuracy": 0.6990893897414208,
      "num_tokens": 30958248.0,
      "step": 29500
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 1.5506186485290527,
      "learning_rate": 3.524074074074074e-05,
      "loss": 1.105,
      "mean_token_accuracy": 0.7002321963012218,
      "num_tokens": 31062124.0,
      "step": 29600
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.70699143409729,
      "learning_rate": 3.519069069069069e-05,
      "loss": 1.0941,
      "mean_token_accuracy": 0.7025836318731308,
      "num_tokens": 31165667.0,
      "step": 29700
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 1.8675718307495117,
      "learning_rate": 3.514064064064064e-05,
      "loss": 1.1116,
      "mean_token_accuracy": 0.6975122117996215,
      "num_tokens": 31268482.0,
      "step": 29800
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 1.5032799243927002,
      "learning_rate": 3.50905905905906e-05,
      "loss": 1.0998,
      "mean_token_accuracy": 0.7031407757103443,
      "num_tokens": 31372198.0,
      "step": 29900
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.61504065990448,
      "learning_rate": 3.504054054054054e-05,
      "loss": 1.1027,
      "mean_token_accuracy": 0.6998680056631565,
      "num_tokens": 31478031.0,
      "step": 30000
    },
    {
      "epoch": 1.3377777777777777,
      "grad_norm": 1.6312673091888428,
      "learning_rate": 3.499049049049049e-05,
      "loss": 1.1209,
      "mean_token_accuracy": 0.6973347838968038,
      "num_tokens": 31584833.0,
      "step": 30100
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 1.6733800172805786,
      "learning_rate": 3.494044044044044e-05,
      "loss": 1.1237,
      "mean_token_accuracy": 0.6940111637115478,
      "num_tokens": 31690148.0,
      "step": 30200
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 1.5827289819717407,
      "learning_rate": 3.489039039039039e-05,
      "loss": 1.1187,
      "mean_token_accuracy": 0.6995053409039974,
      "num_tokens": 31795552.0,
      "step": 30300
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 1.927610158920288,
      "learning_rate": 3.484034034034034e-05,
      "loss": 1.1128,
      "mean_token_accuracy": 0.699063980281353,
      "num_tokens": 31900986.0,
      "step": 30400
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 1.6409823894500732,
      "learning_rate": 3.479029029029029e-05,
      "loss": 1.1036,
      "mean_token_accuracy": 0.7002442562580109,
      "num_tokens": 32005889.0,
      "step": 30500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.8793072700500488,
      "learning_rate": 3.474024024024024e-05,
      "loss": 1.111,
      "mean_token_accuracy": 0.698451418876648,
      "num_tokens": 32111302.0,
      "step": 30600
    },
    {
      "epoch": 1.3644444444444446,
      "grad_norm": 1.5602545738220215,
      "learning_rate": 3.469019019019019e-05,
      "loss": 1.095,
      "mean_token_accuracy": 0.7014037914574146,
      "num_tokens": 32215078.0,
      "step": 30700
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 1.668093204498291,
      "learning_rate": 3.464014014014014e-05,
      "loss": 1.1079,
      "mean_token_accuracy": 0.7003103777766228,
      "num_tokens": 32319960.0,
      "step": 30800
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 1.80268132686615,
      "learning_rate": 3.459009009009009e-05,
      "loss": 1.1066,
      "mean_token_accuracy": 0.7006943140923977,
      "num_tokens": 32425652.0,
      "step": 30900
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 1.6210829019546509,
      "learning_rate": 3.454054054054054e-05,
      "loss": 1.1006,
      "mean_token_accuracy": 0.7001994986832142,
      "num_tokens": 32530552.0,
      "step": 31000
    },
    {
      "epoch": 1.3822222222222222,
      "grad_norm": 1.6956809759140015,
      "learning_rate": 3.449049049049049e-05,
      "loss": 1.107,
      "mean_token_accuracy": 0.7007775628566741,
      "num_tokens": 32634815.0,
      "step": 31100
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 1.631804347038269,
      "learning_rate": 3.444044044044044e-05,
      "loss": 1.1064,
      "mean_token_accuracy": 0.6994907251000404,
      "num_tokens": 32740198.0,
      "step": 31200
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 1.5819646120071411,
      "learning_rate": 3.439039039039039e-05,
      "loss": 1.1301,
      "mean_token_accuracy": 0.6948999418318271,
      "num_tokens": 32845353.0,
      "step": 31300
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 1.718512773513794,
      "learning_rate": 3.434034034034034e-05,
      "loss": 1.1124,
      "mean_token_accuracy": 0.6986088798940182,
      "num_tokens": 32948842.0,
      "step": 31400
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.5600273609161377,
      "learning_rate": 3.429029029029029e-05,
      "loss": 1.1091,
      "mean_token_accuracy": 0.6992652447521687,
      "num_tokens": 33054761.0,
      "step": 31500
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 1.4969630241394043,
      "learning_rate": 3.424024024024024e-05,
      "loss": 1.1196,
      "mean_token_accuracy": 0.6974258655309677,
      "num_tokens": 33159257.0,
      "step": 31600
    },
    {
      "epoch": 1.4088888888888889,
      "grad_norm": 1.592222809791565,
      "learning_rate": 3.419019019019019e-05,
      "loss": 1.1125,
      "mean_token_accuracy": 0.6982441072165966,
      "num_tokens": 33263445.0,
      "step": 31700
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 1.520019769668579,
      "learning_rate": 3.414014014014014e-05,
      "loss": 1.1198,
      "mean_token_accuracy": 0.6987169595062732,
      "num_tokens": 33370173.0,
      "step": 31800
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 1.4708613157272339,
      "learning_rate": 3.409009009009009e-05,
      "loss": 1.1142,
      "mean_token_accuracy": 0.6993708956241608,
      "num_tokens": 33476987.0,
      "step": 31900
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 1.5486146211624146,
      "learning_rate": 3.404004004004004e-05,
      "loss": 1.1061,
      "mean_token_accuracy": 0.6989191559702158,
      "num_tokens": 33580844.0,
      "step": 32000
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 1.6006529331207275,
      "learning_rate": 3.398998998998999e-05,
      "loss": 1.1169,
      "mean_token_accuracy": 0.6982559885829687,
      "num_tokens": 33686064.0,
      "step": 32100
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 1.6447380781173706,
      "learning_rate": 3.393993993993994e-05,
      "loss": 1.0993,
      "mean_token_accuracy": 0.7002473638951778,
      "num_tokens": 33791796.0,
      "step": 32200
    },
    {
      "epoch": 1.4355555555555555,
      "grad_norm": 1.7709935903549194,
      "learning_rate": 3.388988988988989e-05,
      "loss": 1.1115,
      "mean_token_accuracy": 0.6993511319160461,
      "num_tokens": 33896932.0,
      "step": 32300
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.639837622642517,
      "learning_rate": 3.383983983983984e-05,
      "loss": 1.1058,
      "mean_token_accuracy": 0.6974507589638234,
      "num_tokens": 34001199.0,
      "step": 32400
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 1.654197096824646,
      "learning_rate": 3.378978978978979e-05,
      "loss": 1.1014,
      "mean_token_accuracy": 0.6991188722848892,
      "num_tokens": 34104756.0,
      "step": 32500
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 1.6625615358352661,
      "learning_rate": 3.373973973973974e-05,
      "loss": 1.1091,
      "mean_token_accuracy": 0.7006586684286594,
      "num_tokens": 34208881.0,
      "step": 32600
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 1.643269419670105,
      "learning_rate": 3.368968968968969e-05,
      "loss": 1.111,
      "mean_token_accuracy": 0.69822117485106,
      "num_tokens": 34314531.0,
      "step": 32700
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 1.562091588973999,
      "learning_rate": 3.363963963963964e-05,
      "loss": 1.1015,
      "mean_token_accuracy": 0.7026781608164311,
      "num_tokens": 34417737.0,
      "step": 32800
    },
    {
      "epoch": 1.462222222222222,
      "grad_norm": 1.5557371377944946,
      "learning_rate": 3.358958958958959e-05,
      "loss": 1.106,
      "mean_token_accuracy": 0.6999297620356083,
      "num_tokens": 34522210.0,
      "step": 32900
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 1.5578663349151611,
      "learning_rate": 3.3539539539539536e-05,
      "loss": 1.093,
      "mean_token_accuracy": 0.701972591727972,
      "num_tokens": 34626309.0,
      "step": 33000
    },
    {
      "epoch": 1.471111111111111,
      "grad_norm": 1.6567996740341187,
      "learning_rate": 3.3489489489489486e-05,
      "loss": 1.1014,
      "mean_token_accuracy": 0.6989148977398872,
      "num_tokens": 34730949.0,
      "step": 33100
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 1.7393854856491089,
      "learning_rate": 3.343943943943944e-05,
      "loss": 1.1156,
      "mean_token_accuracy": 0.6998766385018825,
      "num_tokens": 34835289.0,
      "step": 33200
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5996191501617432,
      "learning_rate": 3.338938938938939e-05,
      "loss": 1.1051,
      "mean_token_accuracy": 0.6992740272730589,
      "num_tokens": 34940212.0,
      "step": 33300
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 1.7892268896102905,
      "learning_rate": 3.333933933933934e-05,
      "loss": 1.1091,
      "mean_token_accuracy": 0.6988307270407677,
      "num_tokens": 35044803.0,
      "step": 33400
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 1.56597101688385,
      "learning_rate": 3.3289789789789794e-05,
      "loss": 1.1164,
      "mean_token_accuracy": 0.6990735422074795,
      "num_tokens": 35149416.0,
      "step": 33500
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 1.7083418369293213,
      "learning_rate": 3.323973973973974e-05,
      "loss": 1.1109,
      "mean_token_accuracy": 0.6998248033970594,
      "num_tokens": 35254124.0,
      "step": 33600
    },
    {
      "epoch": 1.4977777777777779,
      "grad_norm": 1.5541349649429321,
      "learning_rate": 3.319019019019019e-05,
      "loss": 1.116,
      "mean_token_accuracy": 0.6992777013033629,
      "num_tokens": 35361561.0,
      "step": 33700
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 1.7805818319320679,
      "learning_rate": 3.314014014014014e-05,
      "loss": 1.1191,
      "mean_token_accuracy": 0.6958767817914486,
      "num_tokens": 35465870.0,
      "step": 33800
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 1.9267046451568604,
      "learning_rate": 3.3090090090090095e-05,
      "loss": 1.1196,
      "mean_token_accuracy": 0.697839776352048,
      "num_tokens": 35570628.0,
      "step": 33900
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 1.5995725393295288,
      "learning_rate": 3.3040040040040045e-05,
      "loss": 1.1113,
      "mean_token_accuracy": 0.6979038040339947,
      "num_tokens": 35674709.0,
      "step": 34000
    },
    {
      "epoch": 1.5155555555555555,
      "grad_norm": 1.5260305404663086,
      "learning_rate": 3.298998998998999e-05,
      "loss": 1.1227,
      "mean_token_accuracy": 0.697365989536047,
      "num_tokens": 35781918.0,
      "step": 34100
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.638226866722107,
      "learning_rate": 3.293993993993994e-05,
      "loss": 1.0998,
      "mean_token_accuracy": 0.700605578571558,
      "num_tokens": 35886006.0,
      "step": 34200
    },
    {
      "epoch": 1.5244444444444445,
      "grad_norm": 1.475080132484436,
      "learning_rate": 3.288988988988989e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.703349686190486,
      "num_tokens": 35990188.0,
      "step": 34300
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 1.539222240447998,
      "learning_rate": 3.2839839839839845e-05,
      "loss": 1.0976,
      "mean_token_accuracy": 0.6993342745304107,
      "num_tokens": 36093793.0,
      "step": 34400
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.627611517906189,
      "learning_rate": 3.2789789789789796e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6998718462884426,
      "num_tokens": 36200580.0,
      "step": 34500
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 1.6457548141479492,
      "learning_rate": 3.273973973973974e-05,
      "loss": 1.0988,
      "mean_token_accuracy": 0.7020600444078445,
      "num_tokens": 36304429.0,
      "step": 34600
    },
    {
      "epoch": 1.5422222222222222,
      "grad_norm": 1.5241533517837524,
      "learning_rate": 3.268968968968969e-05,
      "loss": 1.1114,
      "mean_token_accuracy": 0.701176344230771,
      "num_tokens": 36410211.0,
      "step": 34700
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 1.6628899574279785,
      "learning_rate": 3.263963963963964e-05,
      "loss": 1.1169,
      "mean_token_accuracy": 0.6986414007842541,
      "num_tokens": 36516718.0,
      "step": 34800
    },
    {
      "epoch": 1.551111111111111,
      "grad_norm": 1.5901285409927368,
      "learning_rate": 3.258958958958959e-05,
      "loss": 1.0878,
      "mean_token_accuracy": 0.7020266364514828,
      "num_tokens": 36620003.0,
      "step": 34900
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 1.8343180418014526,
      "learning_rate": 3.2539539539539546e-05,
      "loss": 1.1098,
      "mean_token_accuracy": 0.6979836566746235,
      "num_tokens": 36724587.0,
      "step": 35000
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4893020391464233,
      "learning_rate": 3.248948948948949e-05,
      "loss": 1.1095,
      "mean_token_accuracy": 0.6991780196875333,
      "num_tokens": 36830574.0,
      "step": 35100
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 1.7594072818756104,
      "learning_rate": 3.243943943943944e-05,
      "loss": 1.1005,
      "mean_token_accuracy": 0.7004301568865776,
      "num_tokens": 36935697.0,
      "step": 35200
    },
    {
      "epoch": 1.568888888888889,
      "grad_norm": 1.6391042470932007,
      "learning_rate": 3.238938938938939e-05,
      "loss": 1.1028,
      "mean_token_accuracy": 0.7012306356430054,
      "num_tokens": 37041899.0,
      "step": 35300
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 1.7172157764434814,
      "learning_rate": 3.233933933933934e-05,
      "loss": 1.1142,
      "mean_token_accuracy": 0.6992870561778546,
      "num_tokens": 37149176.0,
      "step": 35400
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 1.728562831878662,
      "learning_rate": 3.2289289289289296e-05,
      "loss": 1.1056,
      "mean_token_accuracy": 0.7002855828404426,
      "num_tokens": 37255506.0,
      "step": 35500
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 1.617667555809021,
      "learning_rate": 3.223923923923924e-05,
      "loss": 1.0959,
      "mean_token_accuracy": 0.702240045517683,
      "num_tokens": 37359864.0,
      "step": 35600
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 1.7817648649215698,
      "learning_rate": 3.218918918918919e-05,
      "loss": 1.1172,
      "mean_token_accuracy": 0.6986448312550784,
      "num_tokens": 37464603.0,
      "step": 35700
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 1.603319764137268,
      "learning_rate": 3.213913913913914e-05,
      "loss": 1.0986,
      "mean_token_accuracy": 0.7008544799685478,
      "num_tokens": 37569679.0,
      "step": 35800
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 1.8715064525604248,
      "learning_rate": 3.208958958958959e-05,
      "loss": 1.1019,
      "mean_token_accuracy": 0.7008178506791591,
      "num_tokens": 37675142.0,
      "step": 35900
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4711599349975586,
      "learning_rate": 3.203953953953954e-05,
      "loss": 1.1032,
      "mean_token_accuracy": 0.7006551843881607,
      "num_tokens": 37779021.0,
      "step": 36000
    },
    {
      "epoch": 1.6044444444444443,
      "grad_norm": 1.602729320526123,
      "learning_rate": 3.198948948948949e-05,
      "loss": 1.0983,
      "mean_token_accuracy": 0.7016135543584824,
      "num_tokens": 37883778.0,
      "step": 36100
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 1.483040690422058,
      "learning_rate": 3.193943943943944e-05,
      "loss": 1.1058,
      "mean_token_accuracy": 0.7008344820141792,
      "num_tokens": 37989041.0,
      "step": 36200
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 1.6086598634719849,
      "learning_rate": 3.188938938938939e-05,
      "loss": 1.1041,
      "mean_token_accuracy": 0.7007896532118321,
      "num_tokens": 38093978.0,
      "step": 36300
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 1.6996219158172607,
      "learning_rate": 3.183933933933934e-05,
      "loss": 1.0988,
      "mean_token_accuracy": 0.7011744852364064,
      "num_tokens": 38199506.0,
      "step": 36400
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 1.7444039583206177,
      "learning_rate": 3.178928928928929e-05,
      "loss": 1.1079,
      "mean_token_accuracy": 0.6996754086762667,
      "num_tokens": 38305413.0,
      "step": 36500
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 1.5693641901016235,
      "learning_rate": 3.173923923923924e-05,
      "loss": 1.0839,
      "mean_token_accuracy": 0.7052629168331623,
      "num_tokens": 38409426.0,
      "step": 36600
    },
    {
      "epoch": 1.6311111111111112,
      "grad_norm": 1.7351832389831543,
      "learning_rate": 3.168918918918919e-05,
      "loss": 1.1069,
      "mean_token_accuracy": 0.7007661297917366,
      "num_tokens": 38515394.0,
      "step": 36700
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 1.7325292825698853,
      "learning_rate": 3.163913913913914e-05,
      "loss": 1.1036,
      "mean_token_accuracy": 0.7004991348087788,
      "num_tokens": 38622205.0,
      "step": 36800
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.5896620750427246,
      "learning_rate": 3.158908908908909e-05,
      "loss": 1.1051,
      "mean_token_accuracy": 0.7011605152487754,
      "num_tokens": 38726532.0,
      "step": 36900
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 1.6665534973144531,
      "learning_rate": 3.153903903903904e-05,
      "loss": 1.0946,
      "mean_token_accuracy": 0.7031276047229766,
      "num_tokens": 38830398.0,
      "step": 37000
    },
    {
      "epoch": 1.6488888888888888,
      "grad_norm": 1.519211769104004,
      "learning_rate": 3.1488988988988984e-05,
      "loss": 1.1284,
      "mean_token_accuracy": 0.6950330979377032,
      "num_tokens": 38937338.0,
      "step": 37100
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1.4129067659378052,
      "learning_rate": 3.143893893893894e-05,
      "loss": 1.1054,
      "mean_token_accuracy": 0.7006184184551238,
      "num_tokens": 39044134.0,
      "step": 37200
    },
    {
      "epoch": 1.6577777777777778,
      "grad_norm": 1.5834916830062866,
      "learning_rate": 3.138888888888889e-05,
      "loss": 1.095,
      "mean_token_accuracy": 0.7013878147304058,
      "num_tokens": 39149454.0,
      "step": 37300
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 1.6807818412780762,
      "learning_rate": 3.133883883883884e-05,
      "loss": 1.1028,
      "mean_token_accuracy": 0.6997067281603813,
      "num_tokens": 39251828.0,
      "step": 37400
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.5690346956253052,
      "learning_rate": 3.128878878878879e-05,
      "loss": 1.0924,
      "mean_token_accuracy": 0.7013567316532135,
      "num_tokens": 39355222.0,
      "step": 37500
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 1.6224662065505981,
      "learning_rate": 3.1238738738738735e-05,
      "loss": 1.0967,
      "mean_token_accuracy": 0.7004825106263161,
      "num_tokens": 39460340.0,
      "step": 37600
    },
    {
      "epoch": 1.6755555555555555,
      "grad_norm": 1.5293091535568237,
      "learning_rate": 3.118868868868869e-05,
      "loss": 1.1127,
      "mean_token_accuracy": 0.6985069526731968,
      "num_tokens": 39565949.0,
      "step": 37700
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.6000292301177979,
      "learning_rate": 3.113863863863864e-05,
      "loss": 1.097,
      "mean_token_accuracy": 0.7007679177820683,
      "num_tokens": 39669821.0,
      "step": 37800
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 1.5102958679199219,
      "learning_rate": 3.108858858858859e-05,
      "loss": 1.0955,
      "mean_token_accuracy": 0.7018332426249981,
      "num_tokens": 39774775.0,
      "step": 37900
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 1.56266188621521,
      "learning_rate": 3.103853853853854e-05,
      "loss": 1.1098,
      "mean_token_accuracy": 0.7006591214239597,
      "num_tokens": 39880189.0,
      "step": 38000
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 1.4653292894363403,
      "learning_rate": 3.0988488488488485e-05,
      "loss": 1.1071,
      "mean_token_accuracy": 0.6978504338860512,
      "num_tokens": 39984616.0,
      "step": 38100
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 1.6455591917037964,
      "learning_rate": 3.0938438438438435e-05,
      "loss": 1.1173,
      "mean_token_accuracy": 0.6966370370984077,
      "num_tokens": 40091358.0,
      "step": 38200
    },
    {
      "epoch": 1.7022222222222223,
      "grad_norm": 1.49754798412323,
      "learning_rate": 3.088838838838839e-05,
      "loss": 1.0941,
      "mean_token_accuracy": 0.7006934091448784,
      "num_tokens": 40197542.0,
      "step": 38300
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 1.4805738925933838,
      "learning_rate": 3.083833833833834e-05,
      "loss": 1.115,
      "mean_token_accuracy": 0.6997479392588138,
      "num_tokens": 40303470.0,
      "step": 38400
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 1.418831706047058,
      "learning_rate": 3.078828828828829e-05,
      "loss": 1.108,
      "mean_token_accuracy": 0.6982931866496801,
      "num_tokens": 40409598.0,
      "step": 38500
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 1.4929622411727905,
      "learning_rate": 3.0738238238238236e-05,
      "loss": 1.0986,
      "mean_token_accuracy": 0.7009823432564736,
      "num_tokens": 40514513.0,
      "step": 38600
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.5310949087142944,
      "learning_rate": 3.0688188188188186e-05,
      "loss": 1.1057,
      "mean_token_accuracy": 0.7009045270085335,
      "num_tokens": 40618169.0,
      "step": 38700
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 1.6422888040542603,
      "learning_rate": 3.063813813813814e-05,
      "loss": 1.0986,
      "mean_token_accuracy": 0.7009213306009769,
      "num_tokens": 40722030.0,
      "step": 38800
    },
    {
      "epoch": 1.728888888888889,
      "grad_norm": 1.556090235710144,
      "learning_rate": 3.058808808808809e-05,
      "loss": 1.0971,
      "mean_token_accuracy": 0.7025102386623621,
      "num_tokens": 40827013.0,
      "step": 38900
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 1.5191000699996948,
      "learning_rate": 3.053803803803804e-05,
      "loss": 1.1045,
      "mean_token_accuracy": 0.6993568766117096,
      "num_tokens": 40930647.0,
      "step": 39000
    },
    {
      "epoch": 1.7377777777777776,
      "grad_norm": 1.5298748016357422,
      "learning_rate": 3.0487987987987986e-05,
      "loss": 1.0907,
      "mean_token_accuracy": 0.7005461819469929,
      "num_tokens": 41034312.0,
      "step": 39100
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 1.6183412075042725,
      "learning_rate": 3.043793793793794e-05,
      "loss": 1.0887,
      "mean_token_accuracy": 0.7013895681500435,
      "num_tokens": 41138633.0,
      "step": 39200
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 1.566197156906128,
      "learning_rate": 3.038788788788789e-05,
      "loss": 1.1005,
      "mean_token_accuracy": 0.7016521725058555,
      "num_tokens": 41243960.0,
      "step": 39300
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 1.636108160018921,
      "learning_rate": 3.033783783783784e-05,
      "loss": 1.0983,
      "mean_token_accuracy": 0.7014409053325653,
      "num_tokens": 41347609.0,
      "step": 39400
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 1.557096004486084,
      "learning_rate": 3.0287787787787793e-05,
      "loss": 1.0914,
      "mean_token_accuracy": 0.7008442835509777,
      "num_tokens": 41452640.0,
      "step": 39500
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.8370530605316162,
      "learning_rate": 3.0237737737737736e-05,
      "loss": 1.0897,
      "mean_token_accuracy": 0.7025042000412941,
      "num_tokens": 41557715.0,
      "step": 39600
    },
    {
      "epoch": 1.7644444444444445,
      "grad_norm": 1.6085959672927856,
      "learning_rate": 3.0187687687687686e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.701051195859909,
      "num_tokens": 41661776.0,
      "step": 39700
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 1.4469690322875977,
      "learning_rate": 3.013763763763764e-05,
      "loss": 1.0996,
      "mean_token_accuracy": 0.700721335709095,
      "num_tokens": 41766968.0,
      "step": 39800
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 1.8318980932235718,
      "learning_rate": 3.008758758758759e-05,
      "loss": 1.1085,
      "mean_token_accuracy": 0.699100221246481,
      "num_tokens": 41872555.0,
      "step": 39900
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 1.488340973854065,
      "learning_rate": 3.003803803803804e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6984789729118347,
      "num_tokens": 41976458.0,
      "step": 40000
    },
    {
      "epoch": 1.7822222222222224,
      "grad_norm": 1.5659708976745605,
      "learning_rate": 2.998798798798799e-05,
      "loss": 1.0861,
      "mean_token_accuracy": 0.7055282133817673,
      "num_tokens": 42079260.0,
      "step": 40100
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 1.574790596961975,
      "learning_rate": 2.9937937937937937e-05,
      "loss": 1.0829,
      "mean_token_accuracy": 0.7027554747462272,
      "num_tokens": 42182970.0,
      "step": 40200
    },
    {
      "epoch": 1.791111111111111,
      "grad_norm": 1.6331018209457397,
      "learning_rate": 2.9887887887887887e-05,
      "loss": 1.0929,
      "mean_token_accuracy": 0.7030692569166422,
      "num_tokens": 42289169.0,
      "step": 40300
    },
    {
      "epoch": 1.7955555555555556,
      "grad_norm": 1.5144500732421875,
      "learning_rate": 2.983783783783784e-05,
      "loss": 1.098,
      "mean_token_accuracy": 0.7012197701632976,
      "num_tokens": 42393424.0,
      "step": 40400
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.5336910486221313,
      "learning_rate": 2.978778778778779e-05,
      "loss": 1.0943,
      "mean_token_accuracy": 0.700895719975233,
      "num_tokens": 42498538.0,
      "step": 40500
    },
    {
      "epoch": 1.8044444444444445,
      "grad_norm": 1.598822832107544,
      "learning_rate": 2.9737737737737738e-05,
      "loss": 1.1133,
      "mean_token_accuracy": 0.6989092759788036,
      "num_tokens": 42604439.0,
      "step": 40600
    },
    {
      "epoch": 1.8088888888888888,
      "grad_norm": 1.6330798864364624,
      "learning_rate": 2.9687687687687688e-05,
      "loss": 1.0962,
      "mean_token_accuracy": 0.70146847859025,
      "num_tokens": 42709632.0,
      "step": 40700
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 1.5743879079818726,
      "learning_rate": 2.9637637637637638e-05,
      "loss": 1.1104,
      "mean_token_accuracy": 0.6998310113698244,
      "num_tokens": 42814207.0,
      "step": 40800
    },
    {
      "epoch": 1.8177777777777777,
      "grad_norm": 1.5699729919433594,
      "learning_rate": 2.958758758758759e-05,
      "loss": 1.1121,
      "mean_token_accuracy": 0.6985599114000798,
      "num_tokens": 42919514.0,
      "step": 40900
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 1.5218950510025024,
      "learning_rate": 2.953753753753754e-05,
      "loss": 1.0694,
      "mean_token_accuracy": 0.7063844960927963,
      "num_tokens": 43023157.0,
      "step": 41000
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 1.7331007719039917,
      "learning_rate": 2.9487487487487485e-05,
      "loss": 1.1107,
      "mean_token_accuracy": 0.6993878073990345,
      "num_tokens": 43128687.0,
      "step": 41100
    },
    {
      "epoch": 1.8311111111111111,
      "grad_norm": 1.606919527053833,
      "learning_rate": 2.9437437437437438e-05,
      "loss": 1.1151,
      "mean_token_accuracy": 0.6995342975854874,
      "num_tokens": 43233432.0,
      "step": 41200
    },
    {
      "epoch": 1.8355555555555556,
      "grad_norm": 1.5305721759796143,
      "learning_rate": 2.9387387387387388e-05,
      "loss": 1.1019,
      "mean_token_accuracy": 0.7000674672424794,
      "num_tokens": 43338583.0,
      "step": 41300
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.6501355171203613,
      "learning_rate": 2.9337337337337338e-05,
      "loss": 1.099,
      "mean_token_accuracy": 0.7023277273774147,
      "num_tokens": 43443159.0,
      "step": 41400
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 1.5647727251052856,
      "learning_rate": 2.928728728728729e-05,
      "loss": 1.107,
      "mean_token_accuracy": 0.6998974142968655,
      "num_tokens": 43548350.0,
      "step": 41500
    },
    {
      "epoch": 1.8488888888888888,
      "grad_norm": 1.5751700401306152,
      "learning_rate": 2.9237237237237235e-05,
      "loss": 1.0829,
      "mean_token_accuracy": 0.7024409855902195,
      "num_tokens": 43652868.0,
      "step": 41600
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 1.5914400815963745,
      "learning_rate": 2.918718718718719e-05,
      "loss": 1.0903,
      "mean_token_accuracy": 0.7033991898596287,
      "num_tokens": 43757484.0,
      "step": 41700
    },
    {
      "epoch": 1.8577777777777778,
      "grad_norm": 1.6354122161865234,
      "learning_rate": 2.913713713713714e-05,
      "loss": 1.1129,
      "mean_token_accuracy": 0.6992587938904762,
      "num_tokens": 43862937.0,
      "step": 41800
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 1.6232634782791138,
      "learning_rate": 2.908708708708709e-05,
      "loss": 1.1167,
      "mean_token_accuracy": 0.6979433929920197,
      "num_tokens": 43967916.0,
      "step": 41900
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.4556293487548828,
      "learning_rate": 2.9037037037037042e-05,
      "loss": 1.0867,
      "mean_token_accuracy": 0.7026758769154549,
      "num_tokens": 44071855.0,
      "step": 42000
    },
    {
      "epoch": 1.871111111111111,
      "grad_norm": 1.7035341262817383,
      "learning_rate": 2.8986986986986985e-05,
      "loss": 1.0793,
      "mean_token_accuracy": 0.703881081044674,
      "num_tokens": 44176215.0,
      "step": 42100
    },
    {
      "epoch": 1.8755555555555556,
      "grad_norm": 1.6587709188461304,
      "learning_rate": 2.8937437437437436e-05,
      "loss": 1.093,
      "mean_token_accuracy": 0.7039727920293808,
      "num_tokens": 44280215.0,
      "step": 42200
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.838971734046936,
      "learning_rate": 2.888738738738739e-05,
      "loss": 1.1011,
      "mean_token_accuracy": 0.7025521424412727,
      "num_tokens": 44383826.0,
      "step": 42300
    },
    {
      "epoch": 1.8844444444444446,
      "grad_norm": 1.7134573459625244,
      "learning_rate": 2.883733733733734e-05,
      "loss": 1.0961,
      "mean_token_accuracy": 0.7016763374209404,
      "num_tokens": 44490115.0,
      "step": 42400
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 1.9075497388839722,
      "learning_rate": 2.878728728728729e-05,
      "loss": 1.1142,
      "mean_token_accuracy": 0.698472054079175,
      "num_tokens": 44596199.0,
      "step": 42500
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 1.5681178569793701,
      "learning_rate": 2.873723723723724e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.7037930941581726,
      "num_tokens": 44700568.0,
      "step": 42600
    },
    {
      "epoch": 1.8977777777777778,
      "grad_norm": 1.4670450687408447,
      "learning_rate": 2.8687187187187186e-05,
      "loss": 1.1045,
      "mean_token_accuracy": 0.6991917844116687,
      "num_tokens": 44805260.0,
      "step": 42700
    },
    {
      "epoch": 1.9022222222222223,
      "grad_norm": 1.5322567224502563,
      "learning_rate": 2.8637137137137136e-05,
      "loss": 1.1006,
      "mean_token_accuracy": 0.7004513355344534,
      "num_tokens": 44910527.0,
      "step": 42800
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 1.7742992639541626,
      "learning_rate": 2.858708708708709e-05,
      "loss": 1.12,
      "mean_token_accuracy": 0.6978815642744303,
      "num_tokens": 45015063.0,
      "step": 42900
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 1.5284875631332397,
      "learning_rate": 2.853703703703704e-05,
      "loss": 1.1089,
      "mean_token_accuracy": 0.6988994152843953,
      "num_tokens": 45121116.0,
      "step": 43000
    },
    {
      "epoch": 1.9155555555555557,
      "grad_norm": 1.648447871208191,
      "learning_rate": 2.848698698698699e-05,
      "loss": 1.0919,
      "mean_token_accuracy": 0.7057203006744385,
      "num_tokens": 45226248.0,
      "step": 43100
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.7905871868133545,
      "learning_rate": 2.8436936936936937e-05,
      "loss": 1.0817,
      "mean_token_accuracy": 0.7046389353275299,
      "num_tokens": 45329788.0,
      "step": 43200
    },
    {
      "epoch": 1.9244444444444444,
      "grad_norm": 1.6440625190734863,
      "learning_rate": 2.8386886886886887e-05,
      "loss": 1.0895,
      "mean_token_accuracy": 0.7029709808528424,
      "num_tokens": 45433259.0,
      "step": 43300
    },
    {
      "epoch": 1.9288888888888889,
      "grad_norm": 1.6121158599853516,
      "learning_rate": 2.833683683683684e-05,
      "loss": 1.1097,
      "mean_token_accuracy": 0.6997460984438658,
      "num_tokens": 45537559.0,
      "step": 43400
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 1.487444519996643,
      "learning_rate": 2.828678678678679e-05,
      "loss": 1.1018,
      "mean_token_accuracy": 0.7021729546785355,
      "num_tokens": 45641480.0,
      "step": 43500
    },
    {
      "epoch": 1.9377777777777778,
      "grad_norm": 1.5793707370758057,
      "learning_rate": 2.823673673673674e-05,
      "loss": 1.0953,
      "mean_token_accuracy": 0.7009022442996502,
      "num_tokens": 45746879.0,
      "step": 43600
    },
    {
      "epoch": 1.942222222222222,
      "grad_norm": 1.5648554563522339,
      "learning_rate": 2.8186686686686687e-05,
      "loss": 1.0806,
      "mean_token_accuracy": 0.705483333170414,
      "num_tokens": 45850763.0,
      "step": 43700
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 1.4761930704116821,
      "learning_rate": 2.8136636636636637e-05,
      "loss": 1.1201,
      "mean_token_accuracy": 0.6999845650792121,
      "num_tokens": 45956963.0,
      "step": 43800
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 1.5496243238449097,
      "learning_rate": 2.8086586586586587e-05,
      "loss": 1.0982,
      "mean_token_accuracy": 0.6998810978233814,
      "num_tokens": 46060493.0,
      "step": 43900
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 1.6756004095077515,
      "learning_rate": 2.803653653653654e-05,
      "loss": 1.1106,
      "mean_token_accuracy": 0.6970832350850106,
      "num_tokens": 46167094.0,
      "step": 44000
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.409447193145752,
      "learning_rate": 2.7986486486486484e-05,
      "loss": 1.0973,
      "mean_token_accuracy": 0.7006878797709942,
      "num_tokens": 46272380.0,
      "step": 44100
    },
    {
      "epoch": 1.9644444444444444,
      "grad_norm": 1.737986445426941,
      "learning_rate": 2.7937437437437442e-05,
      "loss": 1.1152,
      "mean_token_accuracy": 0.6997202333807945,
      "num_tokens": 46377688.0,
      "step": 44200
    },
    {
      "epoch": 1.968888888888889,
      "grad_norm": 1.6105055809020996,
      "learning_rate": 2.7887387387387386e-05,
      "loss": 1.1134,
      "mean_token_accuracy": 0.6989703144133091,
      "num_tokens": 46482401.0,
      "step": 44300
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 1.6983237266540527,
      "learning_rate": 2.783733733733734e-05,
      "loss": 1.0904,
      "mean_token_accuracy": 0.7025343985855579,
      "num_tokens": 46586545.0,
      "step": 44400
    },
    {
      "epoch": 1.9777777777777779,
      "grad_norm": 1.6329389810562134,
      "learning_rate": 2.778728728728729e-05,
      "loss": 1.0893,
      "mean_token_accuracy": 0.7028175806999206,
      "num_tokens": 46690803.0,
      "step": 44500
    },
    {
      "epoch": 1.982222222222222,
      "grad_norm": 1.5298712253570557,
      "learning_rate": 2.773723723723724e-05,
      "loss": 1.1045,
      "mean_token_accuracy": 0.7020556776970625,
      "num_tokens": 46795756.0,
      "step": 44600
    },
    {
      "epoch": 1.9866666666666668,
      "grad_norm": 1.6769800186157227,
      "learning_rate": 2.7687187187187186e-05,
      "loss": 1.1008,
      "mean_token_accuracy": 0.703004153817892,
      "num_tokens": 46899746.0,
      "step": 44700
    },
    {
      "epoch": 1.991111111111111,
      "grad_norm": 1.6080033779144287,
      "learning_rate": 2.7637137137137136e-05,
      "loss": 1.1062,
      "mean_token_accuracy": 0.6995716647803784,
      "num_tokens": 47004186.0,
      "step": 44800
    },
    {
      "epoch": 1.9955555555555555,
      "grad_norm": 1.767157793045044,
      "learning_rate": 2.758708708708709e-05,
      "loss": 1.0938,
      "mean_token_accuracy": 0.7020933912694454,
      "num_tokens": 47107934.0,
      "step": 44900
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.5413029193878174,
      "learning_rate": 2.753703703703704e-05,
      "loss": 1.0869,
      "mean_token_accuracy": 0.7039596801251173,
      "num_tokens": 47212418.0,
      "step": 45000
    },
    {
      "epoch": 2.0044444444444443,
      "grad_norm": 1.7170413732528687,
      "learning_rate": 2.748698698698699e-05,
      "loss": 1.1079,
      "mean_token_accuracy": 0.701276407763362,
      "num_tokens": 47316471.0,
      "step": 45100
    },
    {
      "epoch": 2.008888888888889,
      "grad_norm": 1.5618807077407837,
      "learning_rate": 2.7436936936936936e-05,
      "loss": 1.1049,
      "mean_token_accuracy": 0.7031271681934596,
      "num_tokens": 47425813.0,
      "step": 45200
    },
    {
      "epoch": 2.013333333333333,
      "grad_norm": 1.5882587432861328,
      "learning_rate": 2.7386886886886886e-05,
      "loss": 1.0881,
      "mean_token_accuracy": 0.7027053686976433,
      "num_tokens": 47531340.0,
      "step": 45300
    },
    {
      "epoch": 2.017777777777778,
      "grad_norm": 1.6865792274475098,
      "learning_rate": 2.7336836836836836e-05,
      "loss": 1.1092,
      "mean_token_accuracy": 0.7005461311340332,
      "num_tokens": 47637089.0,
      "step": 45400
    },
    {
      "epoch": 2.022222222222222,
      "grad_norm": 1.705260992050171,
      "learning_rate": 2.728678678678679e-05,
      "loss": 1.1169,
      "mean_token_accuracy": 0.6961775174736977,
      "num_tokens": 47742875.0,
      "step": 45500
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 1.5039383172988892,
      "learning_rate": 2.723673673673674e-05,
      "loss": 1.0994,
      "mean_token_accuracy": 0.7026704832911491,
      "num_tokens": 47845899.0,
      "step": 45600
    },
    {
      "epoch": 2.031111111111111,
      "grad_norm": 1.491280436515808,
      "learning_rate": 2.7186686686686687e-05,
      "loss": 1.0682,
      "mean_token_accuracy": 0.706330798715353,
      "num_tokens": 47948999.0,
      "step": 45700
    },
    {
      "epoch": 2.0355555555555553,
      "grad_norm": 1.5623795986175537,
      "learning_rate": 2.7136636636636637e-05,
      "loss": 1.0947,
      "mean_token_accuracy": 0.7023951363563538,
      "num_tokens": 48054666.0,
      "step": 45800
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.6666507720947266,
      "learning_rate": 2.7086586586586587e-05,
      "loss": 1.1088,
      "mean_token_accuracy": 0.6990443970263004,
      "num_tokens": 48159914.0,
      "step": 45900
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 1.7448700666427612,
      "learning_rate": 2.703653653653654e-05,
      "loss": 1.0779,
      "mean_token_accuracy": 0.7051275588572026,
      "num_tokens": 48264330.0,
      "step": 46000
    },
    {
      "epoch": 2.048888888888889,
      "grad_norm": 1.5763771533966064,
      "learning_rate": 2.698648648648649e-05,
      "loss": 1.1143,
      "mean_token_accuracy": 0.6990528218448162,
      "num_tokens": 48371213.0,
      "step": 46100
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 1.7410919666290283,
      "learning_rate": 2.6936436436436437e-05,
      "loss": 1.0944,
      "mean_token_accuracy": 0.7026624399423599,
      "num_tokens": 48476345.0,
      "step": 46200
    },
    {
      "epoch": 2.057777777777778,
      "grad_norm": 1.471861481666565,
      "learning_rate": 2.6886386386386387e-05,
      "loss": 1.0989,
      "mean_token_accuracy": 0.699441563040018,
      "num_tokens": 48580568.0,
      "step": 46300
    },
    {
      "epoch": 2.062222222222222,
      "grad_norm": 1.382780909538269,
      "learning_rate": 2.6836336336336337e-05,
      "loss": 1.0925,
      "mean_token_accuracy": 0.7041740420460701,
      "num_tokens": 48685806.0,
      "step": 46400
    },
    {
      "epoch": 2.066666666666667,
      "grad_norm": 1.7088016271591187,
      "learning_rate": 2.6786286286286287e-05,
      "loss": 1.1096,
      "mean_token_accuracy": 0.7006496168673039,
      "num_tokens": 48791579.0,
      "step": 46500
    },
    {
      "epoch": 2.071111111111111,
      "grad_norm": 1.7453575134277344,
      "learning_rate": 2.673623623623624e-05,
      "loss": 1.1056,
      "mean_token_accuracy": 0.7012094302475452,
      "num_tokens": 48896156.0,
      "step": 46600
    },
    {
      "epoch": 2.0755555555555554,
      "grad_norm": 1.6400648355484009,
      "learning_rate": 2.6686186186186184e-05,
      "loss": 1.0906,
      "mean_token_accuracy": 0.7024191105365754,
      "num_tokens": 48999636.0,
      "step": 46700
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.7109540700912476,
      "learning_rate": 2.6636136136136137e-05,
      "loss": 1.1027,
      "mean_token_accuracy": 0.7001957571506501,
      "num_tokens": 49104822.0,
      "step": 46800
    },
    {
      "epoch": 2.0844444444444443,
      "grad_norm": 1.6422741413116455,
      "learning_rate": 2.6586086086086087e-05,
      "loss": 1.0936,
      "mean_token_accuracy": 0.7036983835697174,
      "num_tokens": 49211039.0,
      "step": 46900
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 1.6288162469863892,
      "learning_rate": 2.6536036036036037e-05,
      "loss": 1.0981,
      "mean_token_accuracy": 0.7027543166279793,
      "num_tokens": 49315017.0,
      "step": 47000
    },
    {
      "epoch": 2.0933333333333333,
      "grad_norm": 1.6066981554031372,
      "learning_rate": 2.648598598598599e-05,
      "loss": 1.1038,
      "mean_token_accuracy": 0.7001777077466249,
      "num_tokens": 49423275.0,
      "step": 47100
    },
    {
      "epoch": 2.097777777777778,
      "grad_norm": 1.5422563552856445,
      "learning_rate": 2.6435935935935934e-05,
      "loss": 1.105,
      "mean_token_accuracy": 0.7020644001662731,
      "num_tokens": 49527224.0,
      "step": 47200
    },
    {
      "epoch": 2.102222222222222,
      "grad_norm": 1.6008596420288086,
      "learning_rate": 2.6385885885885888e-05,
      "loss": 1.0902,
      "mean_token_accuracy": 0.7032253108918667,
      "num_tokens": 49631392.0,
      "step": 47300
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 1.5553010702133179,
      "learning_rate": 2.6335835835835838e-05,
      "loss": 1.0949,
      "mean_token_accuracy": 0.6999450623989105,
      "num_tokens": 49736626.0,
      "step": 47400
    },
    {
      "epoch": 2.111111111111111,
      "grad_norm": 1.5229486227035522,
      "learning_rate": 2.6285785785785788e-05,
      "loss": 1.0954,
      "mean_token_accuracy": 0.7025229766964912,
      "num_tokens": 49840357.0,
      "step": 47500
    },
    {
      "epoch": 2.1155555555555554,
      "grad_norm": 1.3899681568145752,
      "learning_rate": 2.6235735735735738e-05,
      "loss": 1.1,
      "mean_token_accuracy": 0.7019229412078858,
      "num_tokens": 49946308.0,
      "step": 47600
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.675894021987915,
      "learning_rate": 2.6185685685685685e-05,
      "loss": 1.0978,
      "mean_token_accuracy": 0.701764973551035,
      "num_tokens": 50051697.0,
      "step": 47700
    },
    {
      "epoch": 2.1244444444444444,
      "grad_norm": 1.4399887323379517,
      "learning_rate": 2.6135635635635635e-05,
      "loss": 1.0907,
      "mean_token_accuracy": 0.7037071759998799,
      "num_tokens": 50156319.0,
      "step": 47800
    },
    {
      "epoch": 2.128888888888889,
      "grad_norm": 1.3690320253372192,
      "learning_rate": 2.6085585585585588e-05,
      "loss": 1.1236,
      "mean_token_accuracy": 0.6956013910472393,
      "num_tokens": 50263214.0,
      "step": 47900
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.526770830154419,
      "learning_rate": 2.6035535535535538e-05,
      "loss": 1.1102,
      "mean_token_accuracy": 0.6995463519543409,
      "num_tokens": 50368479.0,
      "step": 48000
    },
    {
      "epoch": 2.137777777777778,
      "grad_norm": 1.7290031909942627,
      "learning_rate": 2.5985485485485488e-05,
      "loss": 1.0986,
      "mean_token_accuracy": 0.7011216850578785,
      "num_tokens": 50472589.0,
      "step": 48100
    },
    {
      "epoch": 2.1422222222222222,
      "grad_norm": 1.6908987760543823,
      "learning_rate": 2.5935435435435435e-05,
      "loss": 1.0895,
      "mean_token_accuracy": 0.7023558774590493,
      "num_tokens": 50577083.0,
      "step": 48200
    },
    {
      "epoch": 2.1466666666666665,
      "grad_norm": 1.5363589525222778,
      "learning_rate": 2.5885885885885886e-05,
      "loss": 1.0985,
      "mean_token_accuracy": 0.7014278638362884,
      "num_tokens": 50681670.0,
      "step": 48300
    },
    {
      "epoch": 2.151111111111111,
      "grad_norm": 1.569223403930664,
      "learning_rate": 2.5835835835835836e-05,
      "loss": 1.109,
      "mean_token_accuracy": 0.7013867472112179,
      "num_tokens": 50786071.0,
      "step": 48400
    },
    {
      "epoch": 2.1555555555555554,
      "grad_norm": 1.6416064500808716,
      "learning_rate": 2.578578578578579e-05,
      "loss": 1.1014,
      "mean_token_accuracy": 0.7009809847921133,
      "num_tokens": 50891665.0,
      "step": 48500
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.4561823606491089,
      "learning_rate": 2.573573573573574e-05,
      "loss": 1.1007,
      "mean_token_accuracy": 0.7020476463437081,
      "num_tokens": 50997710.0,
      "step": 48600
    },
    {
      "epoch": 2.1644444444444444,
      "grad_norm": 1.6719321012496948,
      "learning_rate": 2.5685685685685686e-05,
      "loss": 1.1048,
      "mean_token_accuracy": 0.7019686296582222,
      "num_tokens": 51103071.0,
      "step": 48700
    },
    {
      "epoch": 2.168888888888889,
      "grad_norm": 1.7199259996414185,
      "learning_rate": 2.5635635635635636e-05,
      "loss": 1.0859,
      "mean_token_accuracy": 0.7036222369968891,
      "num_tokens": 51207525.0,
      "step": 48800
    },
    {
      "epoch": 2.1733333333333333,
      "grad_norm": 1.49370539188385,
      "learning_rate": 2.5585585585585586e-05,
      "loss": 1.0795,
      "mean_token_accuracy": 0.7047410416603088,
      "num_tokens": 51312059.0,
      "step": 48900
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 1.6757766008377075,
      "learning_rate": 2.5535535535535536e-05,
      "loss": 1.0978,
      "mean_token_accuracy": 0.7029575657844543,
      "num_tokens": 51417741.0,
      "step": 49000
    },
    {
      "epoch": 2.1822222222222223,
      "grad_norm": 1.6429381370544434,
      "learning_rate": 2.548548548548549e-05,
      "loss": 1.0797,
      "mean_token_accuracy": 0.7059969258308411,
      "num_tokens": 51522617.0,
      "step": 49100
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 1.8571139574050903,
      "learning_rate": 2.5435435435435433e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.702421884983778,
      "num_tokens": 51626206.0,
      "step": 49200
    },
    {
      "epoch": 2.1911111111111112,
      "grad_norm": 1.637997031211853,
      "learning_rate": 2.5385385385385386e-05,
      "loss": 1.0976,
      "mean_token_accuracy": 0.7032617230713367,
      "num_tokens": 51730483.0,
      "step": 49300
    },
    {
      "epoch": 2.1955555555555555,
      "grad_norm": 1.6297607421875,
      "learning_rate": 2.5335335335335336e-05,
      "loss": 1.0837,
      "mean_token_accuracy": 0.7041569837927818,
      "num_tokens": 51833728.0,
      "step": 49400
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.4922754764556885,
      "learning_rate": 2.5285285285285286e-05,
      "loss": 1.1016,
      "mean_token_accuracy": 0.7002388615906239,
      "num_tokens": 51938839.0,
      "step": 49500
    },
    {
      "epoch": 2.2044444444444444,
      "grad_norm": 1.3937418460845947,
      "learning_rate": 2.523523523523524e-05,
      "loss": 1.0969,
      "mean_token_accuracy": 0.7024414220452309,
      "num_tokens": 52043479.0,
      "step": 49600
    },
    {
      "epoch": 2.2088888888888887,
      "grad_norm": 1.5437228679656982,
      "learning_rate": 2.5185185185185183e-05,
      "loss": 1.093,
      "mean_token_accuracy": 0.7021192462742328,
      "num_tokens": 52148929.0,
      "step": 49700
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 1.549272060394287,
      "learning_rate": 2.5135135135135133e-05,
      "loss": 1.1009,
      "mean_token_accuracy": 0.6997638492286206,
      "num_tokens": 52253236.0,
      "step": 49800
    },
    {
      "epoch": 2.2177777777777776,
      "grad_norm": 1.6793397665023804,
      "learning_rate": 2.5085085085085087e-05,
      "loss": 1.1186,
      "mean_token_accuracy": 0.6992188565433025,
      "num_tokens": 52358804.0,
      "step": 49900
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.7604012489318848,
      "learning_rate": 2.5035035035035037e-05,
      "loss": 1.1072,
      "mean_token_accuracy": 0.7012540332973003,
      "num_tokens": 52464997.0,
      "step": 50000
    },
    {
      "epoch": 2.2266666666666666,
      "grad_norm": 1.7195929288864136,
      "learning_rate": 2.4984984984984987e-05,
      "loss": 1.0755,
      "mean_token_accuracy": 0.7049261713027954,
      "num_tokens": 52566979.0,
      "step": 50100
    },
    {
      "epoch": 2.2311111111111113,
      "grad_norm": 1.6007965803146362,
      "learning_rate": 2.4934934934934937e-05,
      "loss": 1.0982,
      "mean_token_accuracy": 0.7022611513733864,
      "num_tokens": 52673221.0,
      "step": 50200
    },
    {
      "epoch": 2.2355555555555555,
      "grad_norm": 1.4181923866271973,
      "learning_rate": 2.4884884884884884e-05,
      "loss": 1.1232,
      "mean_token_accuracy": 0.6980248919129372,
      "num_tokens": 52781119.0,
      "step": 50300
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.5305044651031494,
      "learning_rate": 2.4835335335335334e-05,
      "loss": 1.0785,
      "mean_token_accuracy": 0.704738342165947,
      "num_tokens": 52884671.0,
      "step": 50400
    },
    {
      "epoch": 2.2444444444444445,
      "grad_norm": 1.707326054573059,
      "learning_rate": 2.4785285285285288e-05,
      "loss": 1.0792,
      "mean_token_accuracy": 0.7050661081075669,
      "num_tokens": 52989896.0,
      "step": 50500
    },
    {
      "epoch": 2.2488888888888887,
      "grad_norm": 1.5674118995666504,
      "learning_rate": 2.4735235235235235e-05,
      "loss": 1.1003,
      "mean_token_accuracy": 0.7008364756405353,
      "num_tokens": 53094785.0,
      "step": 50600
    },
    {
      "epoch": 2.2533333333333334,
      "grad_norm": 1.8359500169754028,
      "learning_rate": 2.4685185185185185e-05,
      "loss": 1.0966,
      "mean_token_accuracy": 0.7004043890535832,
      "num_tokens": 53199543.0,
      "step": 50700
    },
    {
      "epoch": 2.2577777777777777,
      "grad_norm": 1.5007036924362183,
      "learning_rate": 2.4635135135135138e-05,
      "loss": 1.0953,
      "mean_token_accuracy": 0.702303026765585,
      "num_tokens": 53305353.0,
      "step": 50800
    },
    {
      "epoch": 2.2622222222222224,
      "grad_norm": 1.6812077760696411,
      "learning_rate": 2.4585085085085085e-05,
      "loss": 1.0886,
      "mean_token_accuracy": 0.7032330204546452,
      "num_tokens": 53408619.0,
      "step": 50900
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 2.028951406478882,
      "learning_rate": 2.4535035035035038e-05,
      "loss": 1.1114,
      "mean_token_accuracy": 0.6992493595182896,
      "num_tokens": 53513674.0,
      "step": 51000
    },
    {
      "epoch": 2.2711111111111113,
      "grad_norm": 1.5855460166931152,
      "learning_rate": 2.4484984984984985e-05,
      "loss": 1.0698,
      "mean_token_accuracy": 0.7062650327384472,
      "num_tokens": 53618070.0,
      "step": 51100
    },
    {
      "epoch": 2.2755555555555556,
      "grad_norm": 1.6271806955337524,
      "learning_rate": 2.4434934934934935e-05,
      "loss": 1.1033,
      "mean_token_accuracy": 0.6996482741832734,
      "num_tokens": 53722317.0,
      "step": 51200
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 1.520954966545105,
      "learning_rate": 2.438488488488489e-05,
      "loss": 1.1118,
      "mean_token_accuracy": 0.6995582551509142,
      "num_tokens": 53826878.0,
      "step": 51300
    },
    {
      "epoch": 2.2844444444444445,
      "grad_norm": 1.7342804670333862,
      "learning_rate": 2.4334834834834835e-05,
      "loss": 1.0834,
      "mean_token_accuracy": 0.7045519957691431,
      "num_tokens": 53931202.0,
      "step": 51400
    },
    {
      "epoch": 2.2888888888888888,
      "grad_norm": 1.5381301641464233,
      "learning_rate": 2.4284784784784785e-05,
      "loss": 1.0942,
      "mean_token_accuracy": 0.7018616205453873,
      "num_tokens": 54036188.0,
      "step": 51500
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 1.3962992429733276,
      "learning_rate": 2.4234734734734735e-05,
      "loss": 1.0774,
      "mean_token_accuracy": 0.7066577583551407,
      "num_tokens": 54139323.0,
      "step": 51600
    },
    {
      "epoch": 2.2977777777777777,
      "grad_norm": 1.6120214462280273,
      "learning_rate": 2.4184684684684685e-05,
      "loss": 1.084,
      "mean_token_accuracy": 0.7041451650857925,
      "num_tokens": 54243527.0,
      "step": 51700
    },
    {
      "epoch": 2.3022222222222224,
      "grad_norm": 1.7932878732681274,
      "learning_rate": 2.4134634634634635e-05,
      "loss": 1.1099,
      "mean_token_accuracy": 0.7000174444168806,
      "num_tokens": 54349314.0,
      "step": 51800
    },
    {
      "epoch": 2.3066666666666666,
      "grad_norm": 1.4741346836090088,
      "learning_rate": 2.4084584584584585e-05,
      "loss": 1.0863,
      "mean_token_accuracy": 0.7025511729717254,
      "num_tokens": 54453223.0,
      "step": 51900
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 1.4370031356811523,
      "learning_rate": 2.4034534534534536e-05,
      "loss": 1.0746,
      "mean_token_accuracy": 0.7061948853731156,
      "num_tokens": 54557515.0,
      "step": 52000
    },
    {
      "epoch": 2.3155555555555556,
      "grad_norm": 1.5009530782699585,
      "learning_rate": 2.3984484484484486e-05,
      "loss": 1.0953,
      "mean_token_accuracy": 0.7030105027556419,
      "num_tokens": 54662148.0,
      "step": 52100
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.5237197875976562,
      "learning_rate": 2.3934434434434436e-05,
      "loss": 1.0994,
      "mean_token_accuracy": 0.7044000855088234,
      "num_tokens": 54768067.0,
      "step": 52200
    },
    {
      "epoch": 2.3244444444444445,
      "grad_norm": 1.679880142211914,
      "learning_rate": 2.3884384384384386e-05,
      "loss": 1.0962,
      "mean_token_accuracy": 0.7015336693823337,
      "num_tokens": 54873830.0,
      "step": 52300
    },
    {
      "epoch": 2.328888888888889,
      "grad_norm": 1.5691410303115845,
      "learning_rate": 2.3834334334334336e-05,
      "loss": 1.1036,
      "mean_token_accuracy": 0.7017254573106766,
      "num_tokens": 54977887.0,
      "step": 52400
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 1.588043212890625,
      "learning_rate": 2.3784784784784787e-05,
      "loss": 1.1017,
      "mean_token_accuracy": 0.702516641765833,
      "num_tokens": 55083025.0,
      "step": 52500
    },
    {
      "epoch": 2.3377777777777777,
      "grad_norm": 1.7570130825042725,
      "learning_rate": 2.3734734734734737e-05,
      "loss": 1.1022,
      "mean_token_accuracy": 0.7007115881145001,
      "num_tokens": 55187759.0,
      "step": 52600
    },
    {
      "epoch": 2.3422222222222224,
      "grad_norm": 1.5445008277893066,
      "learning_rate": 2.3684684684684687e-05,
      "loss": 1.0872,
      "mean_token_accuracy": 0.7030526822805405,
      "num_tokens": 55292539.0,
      "step": 52700
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 1.711600661277771,
      "learning_rate": 2.3634634634634637e-05,
      "loss": 1.0972,
      "mean_token_accuracy": 0.7024392279982566,
      "num_tokens": 55398618.0,
      "step": 52800
    },
    {
      "epoch": 2.351111111111111,
      "grad_norm": 1.5466954708099365,
      "learning_rate": 2.3584584584584583e-05,
      "loss": 1.0991,
      "mean_token_accuracy": 0.7039477662742137,
      "num_tokens": 55503960.0,
      "step": 52900
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 1.6592602729797363,
      "learning_rate": 2.3534534534534537e-05,
      "loss": 1.0903,
      "mean_token_accuracy": 0.7038023129105568,
      "num_tokens": 55608428.0,
      "step": 53000
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.534822940826416,
      "learning_rate": 2.3484484484484487e-05,
      "loss": 1.09,
      "mean_token_accuracy": 0.7045167312026024,
      "num_tokens": 55713440.0,
      "step": 53100
    },
    {
      "epoch": 2.3644444444444446,
      "grad_norm": 1.3674930334091187,
      "learning_rate": 2.3434434434434434e-05,
      "loss": 1.1127,
      "mean_token_accuracy": 0.6981346090137959,
      "num_tokens": 55819385.0,
      "step": 53200
    },
    {
      "epoch": 2.368888888888889,
      "grad_norm": 1.5299688577651978,
      "learning_rate": 2.3384384384384387e-05,
      "loss": 1.112,
      "mean_token_accuracy": 0.7000659911334515,
      "num_tokens": 55924756.0,
      "step": 53300
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 1.4977775812149048,
      "learning_rate": 2.3334834834834838e-05,
      "loss": 1.0973,
      "mean_token_accuracy": 0.7021215604245663,
      "num_tokens": 56030531.0,
      "step": 53400
    },
    {
      "epoch": 2.3777777777777778,
      "grad_norm": 1.6777403354644775,
      "learning_rate": 2.3284784784784785e-05,
      "loss": 1.0879,
      "mean_token_accuracy": 0.703456562757492,
      "num_tokens": 56134700.0,
      "step": 53500
    },
    {
      "epoch": 2.3822222222222225,
      "grad_norm": 1.5709419250488281,
      "learning_rate": 2.3234734734734738e-05,
      "loss": 1.092,
      "mean_token_accuracy": 0.7033265870809555,
      "num_tokens": 56239086.0,
      "step": 53600
    },
    {
      "epoch": 2.3866666666666667,
      "grad_norm": 1.5215247869491577,
      "learning_rate": 2.3184684684684685e-05,
      "loss": 1.0777,
      "mean_token_accuracy": 0.7059330014884472,
      "num_tokens": 56343443.0,
      "step": 53700
    },
    {
      "epoch": 2.391111111111111,
      "grad_norm": 1.638527274131775,
      "learning_rate": 2.3134634634634635e-05,
      "loss": 1.0955,
      "mean_token_accuracy": 0.70198396474123,
      "num_tokens": 56448753.0,
      "step": 53800
    },
    {
      "epoch": 2.3955555555555557,
      "grad_norm": 1.7556742429733276,
      "learning_rate": 2.3084584584584588e-05,
      "loss": 1.0987,
      "mean_token_accuracy": 0.7004047083854675,
      "num_tokens": 56554813.0,
      "step": 53900
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.3848963975906372,
      "learning_rate": 2.3034534534534535e-05,
      "loss": 1.0954,
      "mean_token_accuracy": 0.7010575626790524,
      "num_tokens": 56660147.0,
      "step": 54000
    },
    {
      "epoch": 2.4044444444444446,
      "grad_norm": 1.5176101922988892,
      "learning_rate": 2.2984484484484485e-05,
      "loss": 1.0848,
      "mean_token_accuracy": 0.7053752003610134,
      "num_tokens": 56763362.0,
      "step": 54100
    },
    {
      "epoch": 2.408888888888889,
      "grad_norm": 1.7032774686813354,
      "learning_rate": 2.2934434434434435e-05,
      "loss": 1.0883,
      "mean_token_accuracy": 0.7043924593180418,
      "num_tokens": 56866737.0,
      "step": 54200
    },
    {
      "epoch": 2.413333333333333,
      "grad_norm": 1.5601698160171509,
      "learning_rate": 2.2884384384384385e-05,
      "loss": 1.0936,
      "mean_token_accuracy": 0.703894104808569,
      "num_tokens": 56970391.0,
      "step": 54300
    },
    {
      "epoch": 2.417777777777778,
      "grad_norm": 1.6370214223861694,
      "learning_rate": 2.2834334334334335e-05,
      "loss": 1.1048,
      "mean_token_accuracy": 0.7013502518832684,
      "num_tokens": 57074091.0,
      "step": 54400
    },
    {
      "epoch": 2.422222222222222,
      "grad_norm": 1.6043585538864136,
      "learning_rate": 2.2784284284284285e-05,
      "loss": 1.0912,
      "mean_token_accuracy": 0.703451434969902,
      "num_tokens": 57177905.0,
      "step": 54500
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 1.6923702955245972,
      "learning_rate": 2.2734234234234235e-05,
      "loss": 1.0961,
      "mean_token_accuracy": 0.70096396073699,
      "num_tokens": 57283444.0,
      "step": 54600
    },
    {
      "epoch": 2.431111111111111,
      "grad_norm": 1.62208890914917,
      "learning_rate": 2.2684184184184185e-05,
      "loss": 1.0844,
      "mean_token_accuracy": 0.703875640630722,
      "num_tokens": 57387269.0,
      "step": 54700
    },
    {
      "epoch": 2.4355555555555557,
      "grad_norm": 1.868212342262268,
      "learning_rate": 2.2634134134134136e-05,
      "loss": 1.0921,
      "mean_token_accuracy": 0.7017003241181373,
      "num_tokens": 57491928.0,
      "step": 54800
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.579061508178711,
      "learning_rate": 2.2584084084084086e-05,
      "loss": 1.0776,
      "mean_token_accuracy": 0.703873736858368,
      "num_tokens": 57596485.0,
      "step": 54900
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 1.7166656255722046,
      "learning_rate": 2.2534034034034036e-05,
      "loss": 1.1035,
      "mean_token_accuracy": 0.7001921731233597,
      "num_tokens": 57702136.0,
      "step": 55000
    },
    {
      "epoch": 2.448888888888889,
      "grad_norm": 1.6750982999801636,
      "learning_rate": 2.2483983983983986e-05,
      "loss": 1.0711,
      "mean_token_accuracy": 0.7069165002554655,
      "num_tokens": 57806352.0,
      "step": 55100
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 1.5532702207565308,
      "learning_rate": 2.2433933933933936e-05,
      "loss": 1.0843,
      "mean_token_accuracy": 0.7036416327953339,
      "num_tokens": 57910580.0,
      "step": 55200
    },
    {
      "epoch": 2.457777777777778,
      "grad_norm": 1.4897785186767578,
      "learning_rate": 2.2383883883883886e-05,
      "loss": 1.0894,
      "mean_token_accuracy": 0.7032635097205638,
      "num_tokens": 58014993.0,
      "step": 55300
    },
    {
      "epoch": 2.462222222222222,
      "grad_norm": 1.6494163274765015,
      "learning_rate": 2.2333833833833833e-05,
      "loss": 1.0886,
      "mean_token_accuracy": 0.7033637098968029,
      "num_tokens": 58119833.0,
      "step": 55400
    },
    {
      "epoch": 2.466666666666667,
      "grad_norm": 1.6557905673980713,
      "learning_rate": 2.2283783783783786e-05,
      "loss": 1.0882,
      "mean_token_accuracy": 0.7030206614732742,
      "num_tokens": 58225847.0,
      "step": 55500
    },
    {
      "epoch": 2.471111111111111,
      "grad_norm": 1.456318974494934,
      "learning_rate": 2.2233733733733736e-05,
      "loss": 1.0923,
      "mean_token_accuracy": 0.7024973285198212,
      "num_tokens": 58330514.0,
      "step": 55600
    },
    {
      "epoch": 2.4755555555555557,
      "grad_norm": 1.774964451789856,
      "learning_rate": 2.2183683683683683e-05,
      "loss": 1.0847,
      "mean_token_accuracy": 0.7038667315244674,
      "num_tokens": 58434532.0,
      "step": 55700
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.7649887800216675,
      "learning_rate": 2.2133633633633636e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.7025664637982846,
      "num_tokens": 58539846.0,
      "step": 55800
    },
    {
      "epoch": 2.4844444444444447,
      "grad_norm": 1.517257571220398,
      "learning_rate": 2.2083583583583583e-05,
      "loss": 1.0843,
      "mean_token_accuracy": 0.7016245627403259,
      "num_tokens": 58644222.0,
      "step": 55900
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 1.5760281085968018,
      "learning_rate": 2.2033533533533536e-05,
      "loss": 1.0895,
      "mean_token_accuracy": 0.7031501673161984,
      "num_tokens": 58748760.0,
      "step": 56000
    },
    {
      "epoch": 2.493333333333333,
      "grad_norm": 1.619757890701294,
      "learning_rate": 2.1983483483483486e-05,
      "loss": 1.0905,
      "mean_token_accuracy": 0.7017703588306904,
      "num_tokens": 58851929.0,
      "step": 56100
    },
    {
      "epoch": 2.497777777777778,
      "grad_norm": 1.6220759153366089,
      "learning_rate": 2.1933433433433433e-05,
      "loss": 1.0958,
      "mean_token_accuracy": 0.7021837384998798,
      "num_tokens": 58956395.0,
      "step": 56200
    },
    {
      "epoch": 2.502222222222222,
      "grad_norm": 1.6998850107192993,
      "learning_rate": 2.1883383383383387e-05,
      "loss": 1.0904,
      "mean_token_accuracy": 0.702374701499939,
      "num_tokens": 59061981.0,
      "step": 56300
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 1.4163841009140015,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 1.075,
      "mean_token_accuracy": 0.7052570800483227,
      "num_tokens": 59167025.0,
      "step": 56400
    },
    {
      "epoch": 2.511111111111111,
      "grad_norm": 1.6546766757965088,
      "learning_rate": 2.1783283283283283e-05,
      "loss": 1.0939,
      "mean_token_accuracy": 0.7035789959132671,
      "num_tokens": 59270749.0,
      "step": 56500
    },
    {
      "epoch": 2.5155555555555553,
      "grad_norm": 1.6644258499145508,
      "learning_rate": 2.1733233233233237e-05,
      "loss": 1.1023,
      "mean_token_accuracy": 0.6996102849394084,
      "num_tokens": 59376408.0,
      "step": 56600
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.490197777748108,
      "learning_rate": 2.1683183183183183e-05,
      "loss": 1.0896,
      "mean_token_accuracy": 0.7046831707656384,
      "num_tokens": 59482024.0,
      "step": 56700
    },
    {
      "epoch": 2.5244444444444447,
      "grad_norm": 1.441080093383789,
      "learning_rate": 2.1633133133133134e-05,
      "loss": 1.1102,
      "mean_token_accuracy": 0.7013839387893677,
      "num_tokens": 59587023.0,
      "step": 56800
    },
    {
      "epoch": 2.528888888888889,
      "grad_norm": 1.4745594263076782,
      "learning_rate": 2.1583083083083084e-05,
      "loss": 1.0931,
      "mean_token_accuracy": 0.7020942042768001,
      "num_tokens": 59691914.0,
      "step": 56900
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 1.4091925621032715,
      "learning_rate": 2.1533033033033034e-05,
      "loss": 1.0911,
      "mean_token_accuracy": 0.7021395522356033,
      "num_tokens": 59796375.0,
      "step": 57000
    },
    {
      "epoch": 2.537777777777778,
      "grad_norm": 1.5369577407836914,
      "learning_rate": 2.1482982982982984e-05,
      "loss": 1.1068,
      "mean_token_accuracy": 0.7001461401581764,
      "num_tokens": 59902151.0,
      "step": 57100
    },
    {
      "epoch": 2.542222222222222,
      "grad_norm": 1.6997096538543701,
      "learning_rate": 2.1432932932932934e-05,
      "loss": 1.085,
      "mean_token_accuracy": 0.7046594427525997,
      "num_tokens": 60005227.0,
      "step": 57200
    },
    {
      "epoch": 2.546666666666667,
      "grad_norm": 1.7591361999511719,
      "learning_rate": 2.1382882882882884e-05,
      "loss": 1.1231,
      "mean_token_accuracy": 0.6965453410148621,
      "num_tokens": 60110652.0,
      "step": 57300
    },
    {
      "epoch": 2.551111111111111,
      "grad_norm": 1.7474535703659058,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 1.0815,
      "mean_token_accuracy": 0.705298829972744,
      "num_tokens": 60213871.0,
      "step": 57400
    },
    {
      "epoch": 2.5555555555555554,
      "grad_norm": 1.4705649614334106,
      "learning_rate": 2.1283283283283285e-05,
      "loss": 1.1012,
      "mean_token_accuracy": 0.69851713180542,
      "num_tokens": 60317515.0,
      "step": 57500
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.4804309606552124,
      "learning_rate": 2.1233233233233235e-05,
      "loss": 1.0808,
      "mean_token_accuracy": 0.7052694170176983,
      "num_tokens": 60421966.0,
      "step": 57600
    },
    {
      "epoch": 2.5644444444444443,
      "grad_norm": 1.5107876062393188,
      "learning_rate": 2.1183183183183185e-05,
      "loss": 1.0926,
      "mean_token_accuracy": 0.7044776551425457,
      "num_tokens": 60526706.0,
      "step": 57700
    },
    {
      "epoch": 2.568888888888889,
      "grad_norm": 1.7712923288345337,
      "learning_rate": 2.1133133133133135e-05,
      "loss": 1.0833,
      "mean_token_accuracy": 0.7051790228486061,
      "num_tokens": 60631083.0,
      "step": 57800
    },
    {
      "epoch": 2.5733333333333333,
      "grad_norm": 1.4116312265396118,
      "learning_rate": 2.108308308308308e-05,
      "loss": 1.077,
      "mean_token_accuracy": 0.702424601316452,
      "num_tokens": 60735253.0,
      "step": 57900
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 1.567177176475525,
      "learning_rate": 2.1033033033033035e-05,
      "loss": 1.0909,
      "mean_token_accuracy": 0.7023828947544097,
      "num_tokens": 60840427.0,
      "step": 58000
    },
    {
      "epoch": 2.582222222222222,
      "grad_norm": 1.6138505935668945,
      "learning_rate": 2.0982982982982985e-05,
      "loss": 1.0916,
      "mean_token_accuracy": 0.7041474277526141,
      "num_tokens": 60945113.0,
      "step": 58100
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 1.6016814708709717,
      "learning_rate": 2.0932932932932932e-05,
      "loss": 1.1103,
      "mean_token_accuracy": 0.6998107279837131,
      "num_tokens": 61051012.0,
      "step": 58200
    },
    {
      "epoch": 2.591111111111111,
      "grad_norm": 1.384949803352356,
      "learning_rate": 2.0882882882882885e-05,
      "loss": 1.1144,
      "mean_token_accuracy": 0.6979689487814903,
      "num_tokens": 61158819.0,
      "step": 58300
    },
    {
      "epoch": 2.5955555555555554,
      "grad_norm": 1.5775521993637085,
      "learning_rate": 2.0832832832832832e-05,
      "loss": 1.106,
      "mean_token_accuracy": 0.7004072874784469,
      "num_tokens": 61264459.0,
      "step": 58400
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.7191460132598877,
      "learning_rate": 2.0782782782782782e-05,
      "loss": 1.0851,
      "mean_token_accuracy": 0.7044405001401901,
      "num_tokens": 61369398.0,
      "step": 58500
    },
    {
      "epoch": 2.6044444444444443,
      "grad_norm": 1.6587485074996948,
      "learning_rate": 2.0732732732732735e-05,
      "loss": 1.0802,
      "mean_token_accuracy": 0.7046583032608033,
      "num_tokens": 61474524.0,
      "step": 58600
    },
    {
      "epoch": 2.608888888888889,
      "grad_norm": 1.6624716520309448,
      "learning_rate": 2.0682682682682682e-05,
      "loss": 1.0962,
      "mean_token_accuracy": 0.701456720083952,
      "num_tokens": 61579338.0,
      "step": 58700
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 1.46821129322052,
      "learning_rate": 2.0632632632632636e-05,
      "loss": 1.0943,
      "mean_token_accuracy": 0.7015485405921936,
      "num_tokens": 61684868.0,
      "step": 58800
    },
    {
      "epoch": 2.6177777777777775,
      "grad_norm": 1.4510776996612549,
      "learning_rate": 2.0582582582582582e-05,
      "loss": 1.0902,
      "mean_token_accuracy": 0.7011495631188154,
      "num_tokens": 61789336.0,
      "step": 58900
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 1.5907824039459229,
      "learning_rate": 2.0532532532532532e-05,
      "loss": 1.0765,
      "mean_token_accuracy": 0.7050233137607574,
      "num_tokens": 61894628.0,
      "step": 59000
    },
    {
      "epoch": 2.626666666666667,
      "grad_norm": 1.5028120279312134,
      "learning_rate": 2.0482482482482486e-05,
      "loss": 1.0927,
      "mean_token_accuracy": 0.7024231921136379,
      "num_tokens": 62000387.0,
      "step": 59100
    },
    {
      "epoch": 2.631111111111111,
      "grad_norm": 1.708109974861145,
      "learning_rate": 2.0432432432432432e-05,
      "loss": 1.0868,
      "mean_token_accuracy": 0.7033436886966229,
      "num_tokens": 62104892.0,
      "step": 59200
    },
    {
      "epoch": 2.6355555555555554,
      "grad_norm": 1.7236363887786865,
      "learning_rate": 2.0382382382382383e-05,
      "loss": 1.0888,
      "mean_token_accuracy": 0.7040995915234088,
      "num_tokens": 62209019.0,
      "step": 59300
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.5646882057189941,
      "learning_rate": 2.0332332332332333e-05,
      "loss": 1.0993,
      "mean_token_accuracy": 0.7029747886955738,
      "num_tokens": 62314628.0,
      "step": 59400
    },
    {
      "epoch": 2.6444444444444444,
      "grad_norm": 1.6248663663864136,
      "learning_rate": 2.0282782782782783e-05,
      "loss": 1.0951,
      "mean_token_accuracy": 0.7026352892816067,
      "num_tokens": 62418698.0,
      "step": 59500
    },
    {
      "epoch": 2.648888888888889,
      "grad_norm": 1.3280690908432007,
      "learning_rate": 2.0232732732732733e-05,
      "loss": 1.087,
      "mean_token_accuracy": 0.7033412981033326,
      "num_tokens": 62524076.0,
      "step": 59600
    },
    {
      "epoch": 2.6533333333333333,
      "grad_norm": 1.6139098405838013,
      "learning_rate": 2.0182682682682684e-05,
      "loss": 1.0883,
      "mean_token_accuracy": 0.7033982250094414,
      "num_tokens": 62629288.0,
      "step": 59700
    },
    {
      "epoch": 2.6577777777777776,
      "grad_norm": 1.765148639678955,
      "learning_rate": 2.0132632632632634e-05,
      "loss": 1.0841,
      "mean_token_accuracy": 0.7040363562107086,
      "num_tokens": 62733377.0,
      "step": 59800
    },
    {
      "epoch": 2.6622222222222223,
      "grad_norm": 1.4721665382385254,
      "learning_rate": 2.0082582582582584e-05,
      "loss": 1.0917,
      "mean_token_accuracy": 0.7039655813574791,
      "num_tokens": 62838292.0,
      "step": 59900
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.5935921669006348,
      "learning_rate": 2.0032532532532534e-05,
      "loss": 1.0926,
      "mean_token_accuracy": 0.7026566748321056,
      "num_tokens": 62942165.0,
      "step": 60000
    },
    {
      "epoch": 2.671111111111111,
      "grad_norm": 1.5330249071121216,
      "learning_rate": 1.9982482482482484e-05,
      "loss": 1.1123,
      "mean_token_accuracy": 0.6996627201139927,
      "num_tokens": 63047211.0,
      "step": 60100
    },
    {
      "epoch": 2.6755555555555555,
      "grad_norm": 1.5336815118789673,
      "learning_rate": 1.9932432432432434e-05,
      "loss": 1.0888,
      "mean_token_accuracy": 0.703153156042099,
      "num_tokens": 63152074.0,
      "step": 60200
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.6432160139083862,
      "learning_rate": 1.9882382382382384e-05,
      "loss": 1.1064,
      "mean_token_accuracy": 0.6977434140443802,
      "num_tokens": 63256743.0,
      "step": 60300
    },
    {
      "epoch": 2.6844444444444444,
      "grad_norm": 1.6125239133834839,
      "learning_rate": 1.9832332332332334e-05,
      "loss": 1.1025,
      "mean_token_accuracy": 0.7006817377358675,
      "num_tokens": 63361608.0,
      "step": 60400
    },
    {
      "epoch": 2.688888888888889,
      "grad_norm": 1.5147138833999634,
      "learning_rate": 1.9782282282282284e-05,
      "loss": 1.0883,
      "mean_token_accuracy": 0.7045146320015192,
      "num_tokens": 63465946.0,
      "step": 60500
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 1.6233478784561157,
      "learning_rate": 1.9732232232232234e-05,
      "loss": 1.0842,
      "mean_token_accuracy": 0.7037528865039349,
      "num_tokens": 63570873.0,
      "step": 60600
    },
    {
      "epoch": 2.6977777777777776,
      "grad_norm": 1.5826576948165894,
      "learning_rate": 1.968218218218218e-05,
      "loss": 1.0911,
      "mean_token_accuracy": 0.7022295324504375,
      "num_tokens": 63676739.0,
      "step": 60700
    },
    {
      "epoch": 2.7022222222222223,
      "grad_norm": 1.5035400390625,
      "learning_rate": 1.9632132132132134e-05,
      "loss": 1.0969,
      "mean_token_accuracy": 0.7032184968143702,
      "num_tokens": 63782158.0,
      "step": 60800
    },
    {
      "epoch": 2.7066666666666666,
      "grad_norm": 1.618765115737915,
      "learning_rate": 1.9582082082082084e-05,
      "loss": 1.1059,
      "mean_token_accuracy": 0.6989600969851018,
      "num_tokens": 63888583.0,
      "step": 60900
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 1.716092586517334,
      "learning_rate": 1.953203203203203e-05,
      "loss": 1.0825,
      "mean_token_accuracy": 0.7048125292360783,
      "num_tokens": 63994354.0,
      "step": 61000
    },
    {
      "epoch": 2.7155555555555555,
      "grad_norm": 1.7097930908203125,
      "learning_rate": 1.9481981981981985e-05,
      "loss": 1.106,
      "mean_token_accuracy": 0.7013750639557839,
      "num_tokens": 64099853.0,
      "step": 61100
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.6655216217041016,
      "learning_rate": 1.943193193193193e-05,
      "loss": 1.0825,
      "mean_token_accuracy": 0.7051707394421101,
      "num_tokens": 64205261.0,
      "step": 61200
    },
    {
      "epoch": 2.7244444444444444,
      "grad_norm": 1.547644853591919,
      "learning_rate": 1.9381881881881885e-05,
      "loss": 1.0983,
      "mean_token_accuracy": 0.6994652418792248,
      "num_tokens": 64311155.0,
      "step": 61300
    },
    {
      "epoch": 2.728888888888889,
      "grad_norm": 1.4453099966049194,
      "learning_rate": 1.933183183183183e-05,
      "loss": 1.0815,
      "mean_token_accuracy": 0.7037353102862834,
      "num_tokens": 64415304.0,
      "step": 61400
    },
    {
      "epoch": 2.7333333333333334,
      "grad_norm": 1.553442120552063,
      "learning_rate": 1.9282282282282282e-05,
      "loss": 1.0831,
      "mean_token_accuracy": 0.7054813507199288,
      "num_tokens": 64520124.0,
      "step": 61500
    },
    {
      "epoch": 2.7377777777777776,
      "grad_norm": 1.5287011861801147,
      "learning_rate": 1.9232232232232232e-05,
      "loss": 1.0848,
      "mean_token_accuracy": 0.7037609869241714,
      "num_tokens": 64623544.0,
      "step": 61600
    },
    {
      "epoch": 2.7422222222222223,
      "grad_norm": 1.527711272239685,
      "learning_rate": 1.9182182182182182e-05,
      "loss": 1.0852,
      "mean_token_accuracy": 0.7040445451438427,
      "num_tokens": 64728257.0,
      "step": 61700
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 1.580483317375183,
      "learning_rate": 1.9132132132132132e-05,
      "loss": 1.1002,
      "mean_token_accuracy": 0.7013346339762211,
      "num_tokens": 64833695.0,
      "step": 61800
    },
    {
      "epoch": 2.7511111111111113,
      "grad_norm": 1.6420667171478271,
      "learning_rate": 1.9082082082082082e-05,
      "loss": 1.1077,
      "mean_token_accuracy": 0.7020073415338993,
      "num_tokens": 64939821.0,
      "step": 61900
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 1.5090547800064087,
      "learning_rate": 1.9032032032032032e-05,
      "loss": 1.102,
      "mean_token_accuracy": 0.7021152367442847,
      "num_tokens": 65046939.0,
      "step": 62000
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.5545291900634766,
      "learning_rate": 1.8981981981981983e-05,
      "loss": 1.0963,
      "mean_token_accuracy": 0.7027108030021191,
      "num_tokens": 65151285.0,
      "step": 62100
    },
    {
      "epoch": 2.7644444444444445,
      "grad_norm": 1.509967565536499,
      "learning_rate": 1.8931931931931933e-05,
      "loss": 1.075,
      "mean_token_accuracy": 0.7053308838605881,
      "num_tokens": 65255701.0,
      "step": 62200
    },
    {
      "epoch": 2.7688888888888887,
      "grad_norm": 1.460924506187439,
      "learning_rate": 1.8882382382382383e-05,
      "loss": 1.1056,
      "mean_token_accuracy": 0.7012299665808678,
      "num_tokens": 65362485.0,
      "step": 62300
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 1.6154537200927734,
      "learning_rate": 1.8832332332332333e-05,
      "loss": 1.0862,
      "mean_token_accuracy": 0.7030892826616764,
      "num_tokens": 65467032.0,
      "step": 62400
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.6386897563934326,
      "learning_rate": 1.8782282282282284e-05,
      "loss": 1.1023,
      "mean_token_accuracy": 0.7014240013062953,
      "num_tokens": 65572752.0,
      "step": 62500
    },
    {
      "epoch": 2.7822222222222224,
      "grad_norm": 1.5664132833480835,
      "learning_rate": 1.8732232232232234e-05,
      "loss": 1.102,
      "mean_token_accuracy": 0.7008857710659504,
      "num_tokens": 65678407.0,
      "step": 62600
    },
    {
      "epoch": 2.7866666666666666,
      "grad_norm": 1.5248548984527588,
      "learning_rate": 1.8682182182182184e-05,
      "loss": 1.0731,
      "mean_token_accuracy": 0.7047330056130886,
      "num_tokens": 65783957.0,
      "step": 62700
    },
    {
      "epoch": 2.7911111111111113,
      "grad_norm": 1.452055811882019,
      "learning_rate": 1.8632132132132134e-05,
      "loss": 1.092,
      "mean_token_accuracy": 0.7010915786027908,
      "num_tokens": 65888656.0,
      "step": 62800
    },
    {
      "epoch": 2.7955555555555556,
      "grad_norm": 1.6978682279586792,
      "learning_rate": 1.8582082082082084e-05,
      "loss": 1.0819,
      "mean_token_accuracy": 0.7048749670386314,
      "num_tokens": 65993001.0,
      "step": 62900
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.5026298761367798,
      "learning_rate": 1.853203203203203e-05,
      "loss": 1.0845,
      "mean_token_accuracy": 0.7032262785732746,
      "num_tokens": 66098380.0,
      "step": 63000
    },
    {
      "epoch": 2.8044444444444445,
      "grad_norm": 1.7345656156539917,
      "learning_rate": 1.8481981981981984e-05,
      "loss": 1.0759,
      "mean_token_accuracy": 0.70557088971138,
      "num_tokens": 66202359.0,
      "step": 63100
    },
    {
      "epoch": 2.8088888888888888,
      "grad_norm": 1.5364257097244263,
      "learning_rate": 1.8431931931931934e-05,
      "loss": 1.0939,
      "mean_token_accuracy": 0.7034224344789982,
      "num_tokens": 66306476.0,
      "step": 63200
    },
    {
      "epoch": 2.8133333333333335,
      "grad_norm": 1.4723418951034546,
      "learning_rate": 1.838188188188188e-05,
      "loss": 1.092,
      "mean_token_accuracy": 0.7032745225727558,
      "num_tokens": 66410772.0,
      "step": 63300
    },
    {
      "epoch": 2.8177777777777777,
      "grad_norm": 1.5079063177108765,
      "learning_rate": 1.8331831831831834e-05,
      "loss": 1.0678,
      "mean_token_accuracy": 0.7081679092347621,
      "num_tokens": 66515601.0,
      "step": 63400
    },
    {
      "epoch": 2.822222222222222,
      "grad_norm": 1.6090278625488281,
      "learning_rate": 1.828178178178178e-05,
      "loss": 1.0806,
      "mean_token_accuracy": 0.7050583070516586,
      "num_tokens": 66620234.0,
      "step": 63500
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 1.5160702466964722,
      "learning_rate": 1.8231731731731734e-05,
      "loss": 1.0939,
      "mean_token_accuracy": 0.7043253043293953,
      "num_tokens": 66726226.0,
      "step": 63600
    },
    {
      "epoch": 2.8311111111111114,
      "grad_norm": 1.5873929262161255,
      "learning_rate": 1.8181681681681684e-05,
      "loss": 1.0791,
      "mean_token_accuracy": 0.7047286339104175,
      "num_tokens": 66832044.0,
      "step": 63700
    },
    {
      "epoch": 2.8355555555555556,
      "grad_norm": 1.4413453340530396,
      "learning_rate": 1.813163163163163e-05,
      "loss": 1.0987,
      "mean_token_accuracy": 0.702353383153677,
      "num_tokens": 66937686.0,
      "step": 63800
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.7104402780532837,
      "learning_rate": 1.8081581581581584e-05,
      "loss": 1.0966,
      "mean_token_accuracy": 0.7039289347082377,
      "num_tokens": 67043367.0,
      "step": 63900
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 1.8684825897216797,
      "learning_rate": 1.803153153153153e-05,
      "loss": 1.0924,
      "mean_token_accuracy": 0.7042833997309208,
      "num_tokens": 67147941.0,
      "step": 64000
    },
    {
      "epoch": 2.848888888888889,
      "grad_norm": 1.3865009546279907,
      "learning_rate": 1.798148148148148e-05,
      "loss": 1.0853,
      "mean_token_accuracy": 0.7031056648492813,
      "num_tokens": 67251998.0,
      "step": 64100
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 1.6581878662109375,
      "learning_rate": 1.7931431431431435e-05,
      "loss": 1.0896,
      "mean_token_accuracy": 0.7020329277217389,
      "num_tokens": 67356644.0,
      "step": 64200
    },
    {
      "epoch": 2.8577777777777778,
      "grad_norm": 1.445313572883606,
      "learning_rate": 1.788138138138138e-05,
      "loss": 1.0911,
      "mean_token_accuracy": 0.7020152117311954,
      "num_tokens": 67461985.0,
      "step": 64300
    },
    {
      "epoch": 2.862222222222222,
      "grad_norm": 1.539518117904663,
      "learning_rate": 1.783133133133133e-05,
      "loss": 1.0967,
      "mean_token_accuracy": 0.704042237997055,
      "num_tokens": 67566978.0,
      "step": 64400
    },
    {
      "epoch": 2.8666666666666667,
      "grad_norm": 1.6332138776779175,
      "learning_rate": 1.778128128128128e-05,
      "loss": 1.0743,
      "mean_token_accuracy": 0.7043114392459393,
      "num_tokens": 67670802.0,
      "step": 64500
    },
    {
      "epoch": 2.871111111111111,
      "grad_norm": 1.4219199419021606,
      "learning_rate": 1.773123123123123e-05,
      "loss": 1.0922,
      "mean_token_accuracy": 0.7033815544843673,
      "num_tokens": 67776868.0,
      "step": 64600
    },
    {
      "epoch": 2.8755555555555556,
      "grad_norm": 1.862276315689087,
      "learning_rate": 1.7681181181181185e-05,
      "loss": 1.0709,
      "mean_token_accuracy": 0.7074078398942948,
      "num_tokens": 67880262.0,
      "step": 64700
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.5417745113372803,
      "learning_rate": 1.7631131131131132e-05,
      "loss": 1.0781,
      "mean_token_accuracy": 0.7056957633793354,
      "num_tokens": 67984802.0,
      "step": 64800
    },
    {
      "epoch": 2.8844444444444446,
      "grad_norm": 1.453871488571167,
      "learning_rate": 1.7581081081081082e-05,
      "loss": 1.0878,
      "mean_token_accuracy": 0.7023535344004631,
      "num_tokens": 68089092.0,
      "step": 64900
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 1.533111333847046,
      "learning_rate": 1.7531031031031032e-05,
      "loss": 1.0735,
      "mean_token_accuracy": 0.7078826439380645,
      "num_tokens": 68192538.0,
      "step": 65000
    },
    {
      "epoch": 2.8933333333333335,
      "grad_norm": 1.694862723350525,
      "learning_rate": 1.7480980980980982e-05,
      "loss": 1.0853,
      "mean_token_accuracy": 0.7057899153232574,
      "num_tokens": 68299180.0,
      "step": 65100
    },
    {
      "epoch": 2.897777777777778,
      "grad_norm": 1.6415202617645264,
      "learning_rate": 1.7430930930930932e-05,
      "loss": 1.0857,
      "mean_token_accuracy": 0.703896668702364,
      "num_tokens": 68403578.0,
      "step": 65200
    },
    {
      "epoch": 2.902222222222222,
      "grad_norm": 1.6209932565689087,
      "learning_rate": 1.7380880880880882e-05,
      "loss": 1.0862,
      "mean_token_accuracy": 0.703619656264782,
      "num_tokens": 68509728.0,
      "step": 65300
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 1.570424199104309,
      "learning_rate": 1.7330830830830832e-05,
      "loss": 1.0868,
      "mean_token_accuracy": 0.7031354650855064,
      "num_tokens": 68614131.0,
      "step": 65400
    },
    {
      "epoch": 2.911111111111111,
      "grad_norm": 1.594154715538025,
      "learning_rate": 1.7280780780780782e-05,
      "loss": 1.0953,
      "mean_token_accuracy": 0.7031149187684059,
      "num_tokens": 68720289.0,
      "step": 65500
    },
    {
      "epoch": 2.9155555555555557,
      "grad_norm": 1.8249157667160034,
      "learning_rate": 1.7230730730730732e-05,
      "loss": 1.093,
      "mean_token_accuracy": 0.7013250674307346,
      "num_tokens": 68825008.0,
      "step": 65600
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.573176383972168,
      "learning_rate": 1.718068068068068e-05,
      "loss": 1.0942,
      "mean_token_accuracy": 0.7029802042245865,
      "num_tokens": 68930186.0,
      "step": 65700
    },
    {
      "epoch": 2.924444444444444,
      "grad_norm": 1.570870280265808,
      "learning_rate": 1.7130630630630632e-05,
      "loss": 1.0788,
      "mean_token_accuracy": 0.7054017708450556,
      "num_tokens": 69033897.0,
      "step": 65800
    },
    {
      "epoch": 2.928888888888889,
      "grad_norm": 1.7991795539855957,
      "learning_rate": 1.7080580580580582e-05,
      "loss": 1.1016,
      "mean_token_accuracy": 0.7017121544480324,
      "num_tokens": 69138398.0,
      "step": 65900
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 1.6825569868087769,
      "learning_rate": 1.703053053053053e-05,
      "loss": 1.0812,
      "mean_token_accuracy": 0.7061050672829151,
      "num_tokens": 69242060.0,
      "step": 66000
    },
    {
      "epoch": 2.937777777777778,
      "grad_norm": 1.761672854423523,
      "learning_rate": 1.6980480480480483e-05,
      "loss": 1.0865,
      "mean_token_accuracy": 0.7043350282311439,
      "num_tokens": 69347693.0,
      "step": 66100
    },
    {
      "epoch": 2.942222222222222,
      "grad_norm": 1.5065529346466064,
      "learning_rate": 1.693043043043043e-05,
      "loss": 1.0867,
      "mean_token_accuracy": 0.7051711022853852,
      "num_tokens": 69453108.0,
      "step": 66200
    },
    {
      "epoch": 2.9466666666666668,
      "grad_norm": 1.5069985389709473,
      "learning_rate": 1.6880380380380383e-05,
      "loss": 1.0968,
      "mean_token_accuracy": 0.7022638221085071,
      "num_tokens": 69559710.0,
      "step": 66300
    },
    {
      "epoch": 2.951111111111111,
      "grad_norm": 1.4702165126800537,
      "learning_rate": 1.6830830830830834e-05,
      "loss": 1.0836,
      "mean_token_accuracy": 0.7064406278729439,
      "num_tokens": 69663486.0,
      "step": 66400
    },
    {
      "epoch": 2.9555555555555557,
      "grad_norm": 1.621448278427124,
      "learning_rate": 1.678078078078078e-05,
      "loss": 1.0791,
      "mean_token_accuracy": 0.7056901568174362,
      "num_tokens": 69767511.0,
      "step": 66500
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.4047558307647705,
      "learning_rate": 1.673073073073073e-05,
      "loss": 1.09,
      "mean_token_accuracy": 0.7042595407366753,
      "num_tokens": 69872431.0,
      "step": 66600
    },
    {
      "epoch": 2.964444444444444,
      "grad_norm": 1.5502221584320068,
      "learning_rate": 1.6680680680680684e-05,
      "loss": 1.0908,
      "mean_token_accuracy": 0.7030543020367622,
      "num_tokens": 69978432.0,
      "step": 66700
    },
    {
      "epoch": 2.968888888888889,
      "grad_norm": 2.0653436183929443,
      "learning_rate": 1.663063063063063e-05,
      "loss": 1.0862,
      "mean_token_accuracy": 0.7038143204152584,
      "num_tokens": 70082278.0,
      "step": 66800
    },
    {
      "epoch": 2.9733333333333336,
      "grad_norm": 1.4579914808273315,
      "learning_rate": 1.658058058058058e-05,
      "loss": 1.0842,
      "mean_token_accuracy": 0.7036127128452062,
      "num_tokens": 70186349.0,
      "step": 66900
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 1.4271072149276733,
      "learning_rate": 1.653053053053053e-05,
      "loss": 1.0856,
      "mean_token_accuracy": 0.7026278652250767,
      "num_tokens": 70292286.0,
      "step": 67000
    },
    {
      "epoch": 2.982222222222222,
      "grad_norm": 1.6822214126586914,
      "learning_rate": 1.648048048048048e-05,
      "loss": 1.069,
      "mean_token_accuracy": 0.7086552272737027,
      "num_tokens": 70397542.0,
      "step": 67100
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 1.634543538093567,
      "learning_rate": 1.643043043043043e-05,
      "loss": 1.0887,
      "mean_token_accuracy": 0.7020210157334804,
      "num_tokens": 70502453.0,
      "step": 67200
    },
    {
      "epoch": 2.991111111111111,
      "grad_norm": 1.4115076065063477,
      "learning_rate": 1.638038038038038e-05,
      "loss": 1.082,
      "mean_token_accuracy": 0.7032381731271744,
      "num_tokens": 70607447.0,
      "step": 67300
    },
    {
      "epoch": 2.9955555555555557,
      "grad_norm": 1.716050386428833,
      "learning_rate": 1.633083083083083e-05,
      "loss": 1.0994,
      "mean_token_accuracy": 0.701930139362812,
      "num_tokens": 70713700.0,
      "step": 67400
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.6671268939971924,
      "learning_rate": 1.628078078078078e-05,
      "loss": 1.0967,
      "mean_token_accuracy": 0.7029221634566784,
      "num_tokens": 70818627.0,
      "step": 67500
    },
    {
      "epoch": 3.0044444444444443,
      "grad_norm": 1.6460145711898804,
      "learning_rate": 1.623073073073073e-05,
      "loss": 1.0979,
      "mean_token_accuracy": 0.7023489433526993,
      "num_tokens": 70924473.0,
      "step": 67600
    },
    {
      "epoch": 3.008888888888889,
      "grad_norm": 1.6661441326141357,
      "learning_rate": 1.6180680680680682e-05,
      "loss": 1.0705,
      "mean_token_accuracy": 0.7069260753691197,
      "num_tokens": 71027865.0,
      "step": 67700
    },
    {
      "epoch": 3.013333333333333,
      "grad_norm": 1.5407994985580444,
      "learning_rate": 1.6130630630630632e-05,
      "loss": 1.0832,
      "mean_token_accuracy": 0.7021633818745613,
      "num_tokens": 71132918.0,
      "step": 67800
    },
    {
      "epoch": 3.017777777777778,
      "grad_norm": 1.8952479362487793,
      "learning_rate": 1.6080580580580582e-05,
      "loss": 1.0945,
      "mean_token_accuracy": 0.7025155647099018,
      "num_tokens": 71237667.0,
      "step": 67900
    },
    {
      "epoch": 3.022222222222222,
      "grad_norm": 1.5039621591567993,
      "learning_rate": 1.6030530530530532e-05,
      "loss": 1.083,
      "mean_token_accuracy": 0.7031435504555702,
      "num_tokens": 71341793.0,
      "step": 68000
    },
    {
      "epoch": 3.026666666666667,
      "grad_norm": 1.3961294889450073,
      "learning_rate": 1.5980480480480482e-05,
      "loss": 1.0894,
      "mean_token_accuracy": 0.7022498609125614,
      "num_tokens": 71446722.0,
      "step": 68100
    },
    {
      "epoch": 3.031111111111111,
      "grad_norm": 1.3769065141677856,
      "learning_rate": 1.5930930930930933e-05,
      "loss": 1.0951,
      "mean_token_accuracy": 0.7047521975636483,
      "num_tokens": 71554463.0,
      "step": 68200
    },
    {
      "epoch": 3.0355555555555553,
      "grad_norm": 1.468850016593933,
      "learning_rate": 1.5880880880880883e-05,
      "loss": 1.0949,
      "mean_token_accuracy": 0.7031170716881752,
      "num_tokens": 71660773.0,
      "step": 68300
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.4121791124343872,
      "learning_rate": 1.583083083083083e-05,
      "loss": 1.0944,
      "mean_token_accuracy": 0.7040870226919651,
      "num_tokens": 71767489.0,
      "step": 68400
    },
    {
      "epoch": 3.0444444444444443,
      "grad_norm": 1.8636459112167358,
      "learning_rate": 1.5780780780780783e-05,
      "loss": 1.0787,
      "mean_token_accuracy": 0.7059892427921295,
      "num_tokens": 71871917.0,
      "step": 68500
    },
    {
      "epoch": 3.048888888888889,
      "grad_norm": 1.4905657768249512,
      "learning_rate": 1.573073073073073e-05,
      "loss": 1.0961,
      "mean_token_accuracy": 0.7031588296592236,
      "num_tokens": 71977175.0,
      "step": 68600
    },
    {
      "epoch": 3.0533333333333332,
      "grad_norm": 1.7230565547943115,
      "learning_rate": 1.5680680680680683e-05,
      "loss": 1.0893,
      "mean_token_accuracy": 0.7048413965106011,
      "num_tokens": 72081395.0,
      "step": 68700
    },
    {
      "epoch": 3.057777777777778,
      "grad_norm": 1.7472474575042725,
      "learning_rate": 1.5630630630630633e-05,
      "loss": 1.081,
      "mean_token_accuracy": 0.7035442307591439,
      "num_tokens": 72185929.0,
      "step": 68800
    },
    {
      "epoch": 3.062222222222222,
      "grad_norm": 1.5124189853668213,
      "learning_rate": 1.558058058058058e-05,
      "loss": 1.0879,
      "mean_token_accuracy": 0.7037279954552651,
      "num_tokens": 72292327.0,
      "step": 68900
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 1.5365217924118042,
      "learning_rate": 1.5530530530530533e-05,
      "loss": 1.0692,
      "mean_token_accuracy": 0.7047025282680989,
      "num_tokens": 72398180.0,
      "step": 69000
    },
    {
      "epoch": 3.071111111111111,
      "grad_norm": 1.9531058073043823,
      "learning_rate": 1.548048048048048e-05,
      "loss": 1.091,
      "mean_token_accuracy": 0.703998179808259,
      "num_tokens": 72504977.0,
      "step": 69100
    },
    {
      "epoch": 3.0755555555555554,
      "grad_norm": 1.607856035232544,
      "learning_rate": 1.543043043043043e-05,
      "loss": 1.0896,
      "mean_token_accuracy": 0.7038426683843135,
      "num_tokens": 72610036.0,
      "step": 69200
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.5877187252044678,
      "learning_rate": 1.538038038038038e-05,
      "loss": 1.0866,
      "mean_token_accuracy": 0.7052451084554195,
      "num_tokens": 72715914.0,
      "step": 69300
    },
    {
      "epoch": 3.0844444444444443,
      "grad_norm": 1.5332039594650269,
      "learning_rate": 1.533033033033033e-05,
      "loss": 1.0944,
      "mean_token_accuracy": 0.7040186855196953,
      "num_tokens": 72821646.0,
      "step": 69400
    },
    {
      "epoch": 3.088888888888889,
      "grad_norm": 1.7124468088150024,
      "learning_rate": 1.528028028028028e-05,
      "loss": 1.092,
      "mean_token_accuracy": 0.7014948098361492,
      "num_tokens": 72926105.0,
      "step": 69500
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 1.5793484449386597,
      "learning_rate": 1.523023023023023e-05,
      "loss": 1.0766,
      "mean_token_accuracy": 0.7053591713309288,
      "num_tokens": 73029946.0,
      "step": 69600
    },
    {
      "epoch": 3.097777777777778,
      "grad_norm": 1.6938011646270752,
      "learning_rate": 1.518018018018018e-05,
      "loss": 1.0766,
      "mean_token_accuracy": 0.7068228422105313,
      "num_tokens": 73133933.0,
      "step": 69700
    },
    {
      "epoch": 3.102222222222222,
      "grad_norm": 1.6787097454071045,
      "learning_rate": 1.5130130130130129e-05,
      "loss": 1.0992,
      "mean_token_accuracy": 0.7024850038439036,
      "num_tokens": 73241235.0,
      "step": 69800
    },
    {
      "epoch": 3.1066666666666665,
      "grad_norm": 1.4929500818252563,
      "learning_rate": 1.508008008008008e-05,
      "loss": 1.0784,
      "mean_token_accuracy": 0.7051286554336548,
      "num_tokens": 73346165.0,
      "step": 69900
    },
    {
      "epoch": 3.111111111111111,
      "grad_norm": 1.4525083303451538,
      "learning_rate": 1.5030030030030032e-05,
      "loss": 1.0894,
      "mean_token_accuracy": 0.7010793358087539,
      "num_tokens": 73452605.0,
      "step": 70000
    },
    {
      "epoch": 3.1155555555555554,
      "grad_norm": 1.5342872142791748,
      "learning_rate": 1.497997997997998e-05,
      "loss": 1.0925,
      "mean_token_accuracy": 0.7039869780838489,
      "num_tokens": 73556082.0,
      "step": 70100
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.7288540601730347,
      "learning_rate": 1.492992992992993e-05,
      "loss": 1.0939,
      "mean_token_accuracy": 0.703254126906395,
      "num_tokens": 73659563.0,
      "step": 70200
    },
    {
      "epoch": 3.1244444444444444,
      "grad_norm": 1.5463320016860962,
      "learning_rate": 1.487987987987988e-05,
      "loss": 1.0891,
      "mean_token_accuracy": 0.7025734142959118,
      "num_tokens": 73765754.0,
      "step": 70300
    },
    {
      "epoch": 3.128888888888889,
      "grad_norm": 1.516173243522644,
      "learning_rate": 1.4829829829829831e-05,
      "loss": 1.0861,
      "mean_token_accuracy": 0.7034920953959226,
      "num_tokens": 73871451.0,
      "step": 70400
    },
    {
      "epoch": 3.1333333333333333,
      "grad_norm": 1.586124062538147,
      "learning_rate": 1.4779779779779781e-05,
      "loss": 1.0731,
      "mean_token_accuracy": 0.7060317112505436,
      "num_tokens": 73975938.0,
      "step": 70500
    },
    {
      "epoch": 3.137777777777778,
      "grad_norm": 1.6759312152862549,
      "learning_rate": 1.472972972972973e-05,
      "loss": 1.0804,
      "mean_token_accuracy": 0.7048167268931865,
      "num_tokens": 74080272.0,
      "step": 70600
    },
    {
      "epoch": 3.1422222222222222,
      "grad_norm": 1.6433109045028687,
      "learning_rate": 1.4679679679679681e-05,
      "loss": 1.0896,
      "mean_token_accuracy": 0.7028839932382107,
      "num_tokens": 74185120.0,
      "step": 70700
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 1.523556113243103,
      "learning_rate": 1.462962962962963e-05,
      "loss": 1.0908,
      "mean_token_accuracy": 0.7020550085604191,
      "num_tokens": 74289970.0,
      "step": 70800
    },
    {
      "epoch": 3.151111111111111,
      "grad_norm": 1.5369609594345093,
      "learning_rate": 1.457957957957958e-05,
      "loss": 1.0946,
      "mean_token_accuracy": 0.7014171269536018,
      "num_tokens": 74394055.0,
      "step": 70900
    },
    {
      "epoch": 3.1555555555555554,
      "grad_norm": 1.5021744966506958,
      "learning_rate": 1.4529529529529531e-05,
      "loss": 1.0785,
      "mean_token_accuracy": 0.7047237375378609,
      "num_tokens": 74500351.0,
      "step": 71000
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.6421149969100952,
      "learning_rate": 1.447947947947948e-05,
      "loss": 1.0922,
      "mean_token_accuracy": 0.7017953051626682,
      "num_tokens": 74604960.0,
      "step": 71100
    },
    {
      "epoch": 3.1644444444444444,
      "grad_norm": 1.5205938816070557,
      "learning_rate": 1.4429429429429432e-05,
      "loss": 1.0987,
      "mean_token_accuracy": 0.7030623031407595,
      "num_tokens": 74709708.0,
      "step": 71200
    },
    {
      "epoch": 3.168888888888889,
      "grad_norm": 1.6504786014556885,
      "learning_rate": 1.437937937937938e-05,
      "loss": 1.0913,
      "mean_token_accuracy": 0.7017639069259167,
      "num_tokens": 74814390.0,
      "step": 71300
    },
    {
      "epoch": 3.1733333333333333,
      "grad_norm": 1.5761867761611938,
      "learning_rate": 1.432932932932933e-05,
      "loss": 1.093,
      "mean_token_accuracy": 0.7032294002175331,
      "num_tokens": 74919376.0,
      "step": 71400
    },
    {
      "epoch": 3.1777777777777776,
      "grad_norm": 1.5115214586257935,
      "learning_rate": 1.4279279279279282e-05,
      "loss": 1.0934,
      "mean_token_accuracy": 0.701374129652977,
      "num_tokens": 75022524.0,
      "step": 71500
    },
    {
      "epoch": 3.1822222222222223,
      "grad_norm": 1.3900901079177856,
      "learning_rate": 1.422922922922923e-05,
      "loss": 1.0875,
      "mean_token_accuracy": 0.7025959910452366,
      "num_tokens": 75126934.0,
      "step": 71600
    },
    {
      "epoch": 3.1866666666666665,
      "grad_norm": 1.5591281652450562,
      "learning_rate": 1.417917917917918e-05,
      "loss": 1.0878,
      "mean_token_accuracy": 0.703440442532301,
      "num_tokens": 75232439.0,
      "step": 71700
    },
    {
      "epoch": 3.1911111111111112,
      "grad_norm": 1.3683249950408936,
      "learning_rate": 1.4129129129129129e-05,
      "loss": 1.08,
      "mean_token_accuracy": 0.7057627752423287,
      "num_tokens": 75337931.0,
      "step": 71800
    },
    {
      "epoch": 3.1955555555555555,
      "grad_norm": 1.5068473815917969,
      "learning_rate": 1.407907907907908e-05,
      "loss": 1.0834,
      "mean_token_accuracy": 0.7040886877477169,
      "num_tokens": 75442614.0,
      "step": 71900
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.6154433488845825,
      "learning_rate": 1.402902902902903e-05,
      "loss": 1.0884,
      "mean_token_accuracy": 0.7038424348831177,
      "num_tokens": 75545256.0,
      "step": 72000
    },
    {
      "epoch": 3.2044444444444444,
      "grad_norm": 1.6096584796905518,
      "learning_rate": 1.3978978978978979e-05,
      "loss": 1.083,
      "mean_token_accuracy": 0.7035444009304047,
      "num_tokens": 75648537.0,
      "step": 72100
    },
    {
      "epoch": 3.2088888888888887,
      "grad_norm": 1.5823190212249756,
      "learning_rate": 1.392892892892893e-05,
      "loss": 1.0799,
      "mean_token_accuracy": 0.7036659733951092,
      "num_tokens": 75754119.0,
      "step": 72200
    },
    {
      "epoch": 3.2133333333333334,
      "grad_norm": 1.5049152374267578,
      "learning_rate": 1.3878878878878879e-05,
      "loss": 1.0887,
      "mean_token_accuracy": 0.702960565239191,
      "num_tokens": 75859368.0,
      "step": 72300
    },
    {
      "epoch": 3.2177777777777776,
      "grad_norm": 1.523540735244751,
      "learning_rate": 1.3828828828828829e-05,
      "loss": 1.0749,
      "mean_token_accuracy": 0.706404651850462,
      "num_tokens": 75963805.0,
      "step": 72400
    },
    {
      "epoch": 3.2222222222222223,
      "grad_norm": 1.4891986846923828,
      "learning_rate": 1.3778778778778777e-05,
      "loss": 1.1098,
      "mean_token_accuracy": 0.6989991541206837,
      "num_tokens": 76069608.0,
      "step": 72500
    },
    {
      "epoch": 3.2266666666666666,
      "grad_norm": 1.614093542098999,
      "learning_rate": 1.3728728728728729e-05,
      "loss": 1.0849,
      "mean_token_accuracy": 0.7030822350084782,
      "num_tokens": 76174446.0,
      "step": 72600
    },
    {
      "epoch": 3.2311111111111113,
      "grad_norm": 1.5995382070541382,
      "learning_rate": 1.3678678678678681e-05,
      "loss": 1.0895,
      "mean_token_accuracy": 0.703672599196434,
      "num_tokens": 76280161.0,
      "step": 72700
    },
    {
      "epoch": 3.2355555555555555,
      "grad_norm": 1.5714349746704102,
      "learning_rate": 1.362862862862863e-05,
      "loss": 1.1157,
      "mean_token_accuracy": 0.6989889714866877,
      "num_tokens": 76386433.0,
      "step": 72800
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.354304552078247,
      "learning_rate": 1.357857857857858e-05,
      "loss": 1.1015,
      "mean_token_accuracy": 0.7016082982718944,
      "num_tokens": 76490701.0,
      "step": 72900
    },
    {
      "epoch": 3.2444444444444445,
      "grad_norm": 1.4032387733459473,
      "learning_rate": 1.3528528528528528e-05,
      "loss": 1.0924,
      "mean_token_accuracy": 0.7033543737232685,
      "num_tokens": 76595133.0,
      "step": 73000
    },
    {
      "epoch": 3.2488888888888887,
      "grad_norm": 1.5618385076522827,
      "learning_rate": 1.347847847847848e-05,
      "loss": 1.0887,
      "mean_token_accuracy": 0.7036960063874722,
      "num_tokens": 76700557.0,
      "step": 73100
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 1.6033005714416504,
      "learning_rate": 1.342842842842843e-05,
      "loss": 1.0947,
      "mean_token_accuracy": 0.7023809948563575,
      "num_tokens": 76804215.0,
      "step": 73200
    },
    {
      "epoch": 3.2577777777777777,
      "grad_norm": 1.5449705123901367,
      "learning_rate": 1.3378378378378378e-05,
      "loss": 1.0992,
      "mean_token_accuracy": 0.7020299926400184,
      "num_tokens": 76909144.0,
      "step": 73300
    },
    {
      "epoch": 3.2622222222222224,
      "grad_norm": 1.604125738143921,
      "learning_rate": 1.332832832832833e-05,
      "loss": 1.0932,
      "mean_token_accuracy": 0.7018742565810681,
      "num_tokens": 77013364.0,
      "step": 73400
    },
    {
      "epoch": 3.2666666666666666,
      "grad_norm": 1.8000568151474,
      "learning_rate": 1.3278278278278278e-05,
      "loss": 1.0954,
      "mean_token_accuracy": 0.7020231331884861,
      "num_tokens": 77118501.0,
      "step": 73500
    },
    {
      "epoch": 3.2711111111111113,
      "grad_norm": 1.7187340259552002,
      "learning_rate": 1.3228228228228228e-05,
      "loss": 1.0839,
      "mean_token_accuracy": 0.7049273844063282,
      "num_tokens": 77222843.0,
      "step": 73600
    },
    {
      "epoch": 3.2755555555555556,
      "grad_norm": 1.636654019355774,
      "learning_rate": 1.317817817817818e-05,
      "loss": 1.0863,
      "mean_token_accuracy": 0.703407925516367,
      "num_tokens": 77328149.0,
      "step": 73700
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 1.6419309377670288,
      "learning_rate": 1.3128128128128128e-05,
      "loss": 1.0868,
      "mean_token_accuracy": 0.7044228845834732,
      "num_tokens": 77435017.0,
      "step": 73800
    },
    {
      "epoch": 3.2844444444444445,
      "grad_norm": 1.6390879154205322,
      "learning_rate": 1.307807807807808e-05,
      "loss": 1.0868,
      "mean_token_accuracy": 0.7041598227620125,
      "num_tokens": 77540000.0,
      "step": 73900
    },
    {
      "epoch": 3.2888888888888888,
      "grad_norm": 1.548311710357666,
      "learning_rate": 1.3028028028028028e-05,
      "loss": 1.0813,
      "mean_token_accuracy": 0.7042667463421821,
      "num_tokens": 77644438.0,
      "step": 74000
    },
    {
      "epoch": 3.2933333333333334,
      "grad_norm": 1.4750317335128784,
      "learning_rate": 1.2977977977977978e-05,
      "loss": 1.0774,
      "mean_token_accuracy": 0.7045537002384663,
      "num_tokens": 77747803.0,
      "step": 74100
    },
    {
      "epoch": 3.2977777777777777,
      "grad_norm": 1.6611350774765015,
      "learning_rate": 1.292842842842843e-05,
      "loss": 1.0896,
      "mean_token_accuracy": 0.7058115321397781,
      "num_tokens": 77852771.0,
      "step": 74200
    },
    {
      "epoch": 3.3022222222222224,
      "grad_norm": 1.51317298412323,
      "learning_rate": 1.2878378378378378e-05,
      "loss": 1.0746,
      "mean_token_accuracy": 0.705110229998827,
      "num_tokens": 77957236.0,
      "step": 74300
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 1.4845212697982788,
      "learning_rate": 1.282832832832833e-05,
      "loss": 1.0886,
      "mean_token_accuracy": 0.7047263835370541,
      "num_tokens": 78063095.0,
      "step": 74400
    },
    {
      "epoch": 3.311111111111111,
      "grad_norm": 1.9495203495025635,
      "learning_rate": 1.277827827827828e-05,
      "loss": 1.0875,
      "mean_token_accuracy": 0.703662875443697,
      "num_tokens": 78169491.0,
      "step": 74500
    },
    {
      "epoch": 3.3155555555555556,
      "grad_norm": 1.810719609260559,
      "learning_rate": 1.2728228228228228e-05,
      "loss": 1.0929,
      "mean_token_accuracy": 0.7023061691224575,
      "num_tokens": 78273873.0,
      "step": 74600
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.5491571426391602,
      "learning_rate": 1.267817817817818e-05,
      "loss": 1.1028,
      "mean_token_accuracy": 0.7037907837331295,
      "num_tokens": 78381453.0,
      "step": 74700
    },
    {
      "epoch": 3.3244444444444445,
      "grad_norm": 1.3652231693267822,
      "learning_rate": 1.2628128128128128e-05,
      "loss": 1.0932,
      "mean_token_accuracy": 0.7026735205948352,
      "num_tokens": 78486859.0,
      "step": 74800
    },
    {
      "epoch": 3.328888888888889,
      "grad_norm": 1.5847166776657104,
      "learning_rate": 1.2578078078078078e-05,
      "loss": 1.0814,
      "mean_token_accuracy": 0.7062329821288585,
      "num_tokens": 78591923.0,
      "step": 74900
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.5082924365997314,
      "learning_rate": 1.252802802802803e-05,
      "loss": 1.0841,
      "mean_token_accuracy": 0.7038757263123989,
      "num_tokens": 78697488.0,
      "step": 75000
    },
    {
      "epoch": 3.3377777777777777,
      "grad_norm": 1.5612609386444092,
      "learning_rate": 1.2477977977977978e-05,
      "loss": 1.0721,
      "mean_token_accuracy": 0.7073980164527893,
      "num_tokens": 78801772.0,
      "step": 75100
    },
    {
      "epoch": 3.3422222222222224,
      "grad_norm": 1.8100119829177856,
      "learning_rate": 1.2427927927927928e-05,
      "loss": 1.0778,
      "mean_token_accuracy": 0.7062631405889988,
      "num_tokens": 78906762.0,
      "step": 75200
    },
    {
      "epoch": 3.3466666666666667,
      "grad_norm": 1.8817535638809204,
      "learning_rate": 1.2377877877877878e-05,
      "loss": 1.0983,
      "mean_token_accuracy": 0.7035841611027718,
      "num_tokens": 79013433.0,
      "step": 75300
    },
    {
      "epoch": 3.351111111111111,
      "grad_norm": 1.8005590438842773,
      "learning_rate": 1.2327827827827828e-05,
      "loss": 1.0915,
      "mean_token_accuracy": 0.7038160400092601,
      "num_tokens": 79118236.0,
      "step": 75400
    },
    {
      "epoch": 3.3555555555555556,
      "grad_norm": 1.7714450359344482,
      "learning_rate": 1.2277777777777778e-05,
      "loss": 1.0872,
      "mean_token_accuracy": 0.7042328998446464,
      "num_tokens": 79223818.0,
      "step": 75500
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.555180549621582,
      "learning_rate": 1.2227727727727729e-05,
      "loss": 1.0774,
      "mean_token_accuracy": 0.7053185175359249,
      "num_tokens": 79328767.0,
      "step": 75600
    },
    {
      "epoch": 3.3644444444444446,
      "grad_norm": 1.47752046585083,
      "learning_rate": 1.2177677677677677e-05,
      "loss": 1.0846,
      "mean_token_accuracy": 0.7046977643668652,
      "num_tokens": 79432758.0,
      "step": 75700
    },
    {
      "epoch": 3.368888888888889,
      "grad_norm": 1.6996917724609375,
      "learning_rate": 1.2127627627627629e-05,
      "loss": 1.0749,
      "mean_token_accuracy": 0.7044318847358226,
      "num_tokens": 79536187.0,
      "step": 75800
    },
    {
      "epoch": 3.3733333333333335,
      "grad_norm": 1.5385973453521729,
      "learning_rate": 1.2077577577577579e-05,
      "loss": 1.1073,
      "mean_token_accuracy": 0.7017233657836914,
      "num_tokens": 79642095.0,
      "step": 75900
    },
    {
      "epoch": 3.3777777777777778,
      "grad_norm": 1.5659762620925903,
      "learning_rate": 1.2027527527527529e-05,
      "loss": 1.0963,
      "mean_token_accuracy": 0.7022931738197804,
      "num_tokens": 79746575.0,
      "step": 76000
    },
    {
      "epoch": 3.3822222222222225,
      "grad_norm": 1.6202653646469116,
      "learning_rate": 1.1977477477477477e-05,
      "loss": 1.0776,
      "mean_token_accuracy": 0.7060879565775394,
      "num_tokens": 79849549.0,
      "step": 76100
    },
    {
      "epoch": 3.3866666666666667,
      "grad_norm": 1.4977543354034424,
      "learning_rate": 1.1927427427427427e-05,
      "loss": 1.0719,
      "mean_token_accuracy": 0.7055706891417504,
      "num_tokens": 79954708.0,
      "step": 76200
    },
    {
      "epoch": 3.391111111111111,
      "grad_norm": 1.6067742109298706,
      "learning_rate": 1.1877877877877878e-05,
      "loss": 1.0802,
      "mean_token_accuracy": 0.7047946311533451,
      "num_tokens": 80060610.0,
      "step": 76300
    },
    {
      "epoch": 3.3955555555555557,
      "grad_norm": 1.5925856828689575,
      "learning_rate": 1.1827827827827828e-05,
      "loss": 1.0912,
      "mean_token_accuracy": 0.7023496803641319,
      "num_tokens": 80164250.0,
      "step": 76400
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.6359082460403442,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 1.0763,
      "mean_token_accuracy": 0.7043715460598469,
      "num_tokens": 80268290.0,
      "step": 76500
    },
    {
      "epoch": 3.4044444444444446,
      "grad_norm": 1.459993600845337,
      "learning_rate": 1.1727727727727728e-05,
      "loss": 1.0884,
      "mean_token_accuracy": 0.7039982709288597,
      "num_tokens": 80373444.0,
      "step": 76600
    },
    {
      "epoch": 3.408888888888889,
      "grad_norm": 1.6784892082214355,
      "learning_rate": 1.1677677677677678e-05,
      "loss": 1.0867,
      "mean_token_accuracy": 0.7046155403554439,
      "num_tokens": 80477698.0,
      "step": 76700
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 1.5854148864746094,
      "learning_rate": 1.1627627627627628e-05,
      "loss": 1.078,
      "mean_token_accuracy": 0.7045229065418244,
      "num_tokens": 80582481.0,
      "step": 76800
    },
    {
      "epoch": 3.417777777777778,
      "grad_norm": 1.5370744466781616,
      "learning_rate": 1.1577577577577578e-05,
      "loss": 1.0875,
      "mean_token_accuracy": 0.7042758453637361,
      "num_tokens": 80688804.0,
      "step": 76900
    },
    {
      "epoch": 3.422222222222222,
      "grad_norm": 1.481372356414795,
      "learning_rate": 1.1527527527527528e-05,
      "loss": 1.0737,
      "mean_token_accuracy": 0.7047222615778446,
      "num_tokens": 80793456.0,
      "step": 77000
    },
    {
      "epoch": 3.4266666666666667,
      "grad_norm": 1.5891698598861694,
      "learning_rate": 1.1477477477477477e-05,
      "loss": 1.0812,
      "mean_token_accuracy": 0.7035060030221939,
      "num_tokens": 80898394.0,
      "step": 77100
    },
    {
      "epoch": 3.431111111111111,
      "grad_norm": 1.5348221063613892,
      "learning_rate": 1.1427427427427429e-05,
      "loss": 1.08,
      "mean_token_accuracy": 0.7058073826134205,
      "num_tokens": 81003384.0,
      "step": 77200
    },
    {
      "epoch": 3.4355555555555557,
      "grad_norm": 1.533945918083191,
      "learning_rate": 1.1377377377377379e-05,
      "loss": 1.087,
      "mean_token_accuracy": 0.7030889004468918,
      "num_tokens": 81109269.0,
      "step": 77300
    },
    {
      "epoch": 3.44,
      "grad_norm": 1.7043161392211914,
      "learning_rate": 1.1327327327327327e-05,
      "loss": 1.0924,
      "mean_token_accuracy": 0.7061332046985627,
      "num_tokens": 81213674.0,
      "step": 77400
    },
    {
      "epoch": 3.4444444444444446,
      "grad_norm": 1.5858378410339355,
      "learning_rate": 1.1277277277277277e-05,
      "loss": 1.0765,
      "mean_token_accuracy": 0.7054075939953327,
      "num_tokens": 81318105.0,
      "step": 77500
    },
    {
      "epoch": 3.448888888888889,
      "grad_norm": 1.4661493301391602,
      "learning_rate": 1.1227227227227227e-05,
      "loss": 1.0803,
      "mean_token_accuracy": 0.7042948588728905,
      "num_tokens": 81422421.0,
      "step": 77600
    },
    {
      "epoch": 3.453333333333333,
      "grad_norm": 1.4857561588287354,
      "learning_rate": 1.1177177177177179e-05,
      "loss": 1.0902,
      "mean_token_accuracy": 0.7035063841938972,
      "num_tokens": 81528242.0,
      "step": 77700
    },
    {
      "epoch": 3.457777777777778,
      "grad_norm": 1.7513563632965088,
      "learning_rate": 1.1127127127127127e-05,
      "loss": 1.0946,
      "mean_token_accuracy": 0.7041566261649131,
      "num_tokens": 81634051.0,
      "step": 77800
    },
    {
      "epoch": 3.462222222222222,
      "grad_norm": 1.7496417760849,
      "learning_rate": 1.1077077077077077e-05,
      "loss": 1.0873,
      "mean_token_accuracy": 0.7053505119681358,
      "num_tokens": 81739602.0,
      "step": 77900
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 1.5819774866104126,
      "learning_rate": 1.1027027027027027e-05,
      "loss": 1.1049,
      "mean_token_accuracy": 0.703843524903059,
      "num_tokens": 81845144.0,
      "step": 78000
    },
    {
      "epoch": 3.471111111111111,
      "grad_norm": 1.7873868942260742,
      "learning_rate": 1.0976976976976978e-05,
      "loss": 1.0703,
      "mean_token_accuracy": 0.7074110098183155,
      "num_tokens": 81949537.0,
      "step": 78100
    },
    {
      "epoch": 3.4755555555555557,
      "grad_norm": 1.5577665567398071,
      "learning_rate": 1.0926926926926928e-05,
      "loss": 1.0864,
      "mean_token_accuracy": 0.7036063589155674,
      "num_tokens": 82054260.0,
      "step": 78200
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.641920566558838,
      "learning_rate": 1.0876876876876878e-05,
      "loss": 1.0873,
      "mean_token_accuracy": 0.7068360999226571,
      "num_tokens": 82160805.0,
      "step": 78300
    },
    {
      "epoch": 3.4844444444444447,
      "grad_norm": 1.434203863143921,
      "learning_rate": 1.0826826826826828e-05,
      "loss": 1.0828,
      "mean_token_accuracy": 0.7030437006056309,
      "num_tokens": 82265732.0,
      "step": 78400
    },
    {
      "epoch": 3.488888888888889,
      "grad_norm": 1.6363413333892822,
      "learning_rate": 1.0777277277277279e-05,
      "loss": 1.0766,
      "mean_token_accuracy": 0.7044253391027451,
      "num_tokens": 82370357.0,
      "step": 78500
    },
    {
      "epoch": 3.493333333333333,
      "grad_norm": 1.541783332824707,
      "learning_rate": 1.0727227227227229e-05,
      "loss": 1.0728,
      "mean_token_accuracy": 0.7076493692398071,
      "num_tokens": 82473277.0,
      "step": 78600
    },
    {
      "epoch": 3.497777777777778,
      "grad_norm": 1.4771850109100342,
      "learning_rate": 1.0677177177177177e-05,
      "loss": 1.0767,
      "mean_token_accuracy": 0.7055210037529469,
      "num_tokens": 82577287.0,
      "step": 78700
    },
    {
      "epoch": 3.502222222222222,
      "grad_norm": 1.9012339115142822,
      "learning_rate": 1.0627127127127127e-05,
      "loss": 1.0692,
      "mean_token_accuracy": 0.7084331111609936,
      "num_tokens": 82681320.0,
      "step": 78800
    },
    {
      "epoch": 3.506666666666667,
      "grad_norm": 1.8120914697647095,
      "learning_rate": 1.0577077077077077e-05,
      "loss": 1.0737,
      "mean_token_accuracy": 0.7065223605930805,
      "num_tokens": 82785723.0,
      "step": 78900
    },
    {
      "epoch": 3.511111111111111,
      "grad_norm": 1.598711609840393,
      "learning_rate": 1.0527027027027027e-05,
      "loss": 1.0694,
      "mean_token_accuracy": 0.7068930594623088,
      "num_tokens": 82889783.0,
      "step": 79000
    },
    {
      "epoch": 3.5155555555555553,
      "grad_norm": 1.5400242805480957,
      "learning_rate": 1.0476976976976977e-05,
      "loss": 1.0789,
      "mean_token_accuracy": 0.7063422191143036,
      "num_tokens": 82993655.0,
      "step": 79100
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.8162226676940918,
      "learning_rate": 1.0426926926926927e-05,
      "loss": 1.0876,
      "mean_token_accuracy": 0.7035302867740393,
      "num_tokens": 83098143.0,
      "step": 79200
    },
    {
      "epoch": 3.5244444444444447,
      "grad_norm": 1.3039305210113525,
      "learning_rate": 1.0376876876876877e-05,
      "loss": 1.0718,
      "mean_token_accuracy": 0.7054280469566584,
      "num_tokens": 83201882.0,
      "step": 79300
    },
    {
      "epoch": 3.528888888888889,
      "grad_norm": 1.6412429809570312,
      "learning_rate": 1.0326826826826827e-05,
      "loss": 1.0951,
      "mean_token_accuracy": 0.7024317741394043,
      "num_tokens": 83307759.0,
      "step": 79400
    },
    {
      "epoch": 3.533333333333333,
      "grad_norm": 1.6604235172271729,
      "learning_rate": 1.0276776776776776e-05,
      "loss": 1.0874,
      "mean_token_accuracy": 0.7041125071048736,
      "num_tokens": 83411809.0,
      "step": 79500
    },
    {
      "epoch": 3.537777777777778,
      "grad_norm": 1.6754482984542847,
      "learning_rate": 1.0226726726726728e-05,
      "loss": 1.0837,
      "mean_token_accuracy": 0.7044028770923615,
      "num_tokens": 83517229.0,
      "step": 79600
    },
    {
      "epoch": 3.542222222222222,
      "grad_norm": 1.689318060874939,
      "learning_rate": 1.0176676676676678e-05,
      "loss": 1.0815,
      "mean_token_accuracy": 0.7048877754807472,
      "num_tokens": 83623480.0,
      "step": 79700
    },
    {
      "epoch": 3.546666666666667,
      "grad_norm": 1.765834093093872,
      "learning_rate": 1.0126626626626628e-05,
      "loss": 1.0865,
      "mean_token_accuracy": 0.7041786801815033,
      "num_tokens": 83727517.0,
      "step": 79800
    },
    {
      "epoch": 3.551111111111111,
      "grad_norm": 1.469423532485962,
      "learning_rate": 1.0076576576576576e-05,
      "loss": 1.0887,
      "mean_token_accuracy": 0.7040690045058727,
      "num_tokens": 83831443.0,
      "step": 79900
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 1.655792474746704,
      "learning_rate": 1.0026526526526526e-05,
      "loss": 1.084,
      "mean_token_accuracy": 0.7044393107295036,
      "num_tokens": 83936129.0,
      "step": 80000
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.7910312414169312,
      "learning_rate": 9.976976976976977e-06,
      "loss": 1.1012,
      "mean_token_accuracy": 0.7014265544712543,
      "num_tokens": 84041774.0,
      "step": 80100
    },
    {
      "epoch": 3.5644444444444443,
      "grad_norm": 1.5488096475601196,
      "learning_rate": 9.926926926926927e-06,
      "loss": 1.0888,
      "mean_token_accuracy": 0.70392681568861,
      "num_tokens": 84146210.0,
      "step": 80200
    },
    {
      "epoch": 3.568888888888889,
      "grad_norm": 1.9000133275985718,
      "learning_rate": 9.876876876876877e-06,
      "loss": 1.0844,
      "mean_token_accuracy": 0.7036181333661079,
      "num_tokens": 84250498.0,
      "step": 80300
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 1.6224806308746338,
      "learning_rate": 9.826826826826827e-06,
      "loss": 1.0849,
      "mean_token_accuracy": 0.7049171748757362,
      "num_tokens": 84356032.0,
      "step": 80400
    },
    {
      "epoch": 3.5777777777777775,
      "grad_norm": 1.5272550582885742,
      "learning_rate": 9.776776776776777e-06,
      "loss": 1.0782,
      "mean_token_accuracy": 0.7043790544569493,
      "num_tokens": 84461802.0,
      "step": 80500
    },
    {
      "epoch": 3.582222222222222,
      "grad_norm": 1.491603136062622,
      "learning_rate": 9.726726726726727e-06,
      "loss": 1.0875,
      "mean_token_accuracy": 0.7024290135502815,
      "num_tokens": 84567716.0,
      "step": 80600
    },
    {
      "epoch": 3.586666666666667,
      "grad_norm": 1.7743937969207764,
      "learning_rate": 9.676676676676677e-06,
      "loss": 1.0832,
      "mean_token_accuracy": 0.7049313101172447,
      "num_tokens": 84673211.0,
      "step": 80700
    },
    {
      "epoch": 3.591111111111111,
      "grad_norm": 1.5188117027282715,
      "learning_rate": 9.626626626626627e-06,
      "loss": 1.087,
      "mean_token_accuracy": 0.7042282454669475,
      "num_tokens": 84777577.0,
      "step": 80800
    },
    {
      "epoch": 3.5955555555555554,
      "grad_norm": 1.4264318943023682,
      "learning_rate": 9.576576576576576e-06,
      "loss": 1.0814,
      "mean_token_accuracy": 0.7037063530087471,
      "num_tokens": 84881629.0,
      "step": 80900
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.6195149421691895,
      "learning_rate": 9.526526526526528e-06,
      "loss": 1.0954,
      "mean_token_accuracy": 0.7020487295091152,
      "num_tokens": 84987630.0,
      "step": 81000
    }
  ],
  "logging_steps": 100,
  "max_steps": 100000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.99572657726292e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
